{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.cuda import memory_allocated, empty_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Í≥ºÏùº class_id ÌôïÏù∏(ÏÉùÎûµ Í∞ÄÎä•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í≥ºÏùº class_id ÌôïÏù∏\n",
    "# model = YOLO('yolov8m.pt')\n",
    "# yolo_result = model('../tmp_data/train_data/nothing_0.jpg', agnostic_nms=True)[0]\n",
    "# detections = sv.Detections.from_yolov8(yolo_result)\n",
    "# print(detections.class_id)\n",
    "# print(model.model.names[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ïä§ÏºàÎ†àÌÜ§ Ï∂îÎ°† Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "attention_dot = [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "\n",
    "draw_line = [[11, 12], [11, 23], [12, 24], [23, 24],\n",
    "             [11, 13], [13, 15], [15, 17], [17, 19], [15, 21],\n",
    "             [12, 14], [14, 16], [16, 18], [18, 20], [16, 22]]\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(\n",
    "        thickness=2,\n",
    "        text_thickness=2,\n",
    "        text_scale=1\n",
    "    )\n",
    " \n",
    "def show_skeleton(video_path , interval, attention_dot, draw_line):\n",
    "    model = YOLO('../checkpoint/yolo_pt/best.pt')\n",
    "    \n",
    "    xy_list_list, xy_list_list_flip = [], []\n",
    "    cv2.destroyAllWindows()\n",
    "    pose = mp_pose.Pose(static_image_mode = True, model_complexity = 1, enable_segmentation = False, min_detection_confidence = 0.3)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if cap.isOpened():\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            if cnt == interval and ret == True:\n",
    "                cnt = 0\n",
    "                xy_list, xy_list_flip = [], []\n",
    "                img = cv2.resize(img, (640,  640))\n",
    "                img = cv2.flip(img, 0) # ÏÉÅÌïò Î∞òÏ†Ñ\n",
    "                img = cv2.flip(img, 1) # Ï¢åÏö∞ Î∞òÏ†Ñ\n",
    "                yolo_result = model(img, agnostic_nms=True)[0]\n",
    "                detections = sv.Detections.from_yolov8(yolo_result)\n",
    "                \n",
    "                # selected_classes = [0, 1, 2, 3, 4] # 46: banana, 47 : apple, 49: orange \n",
    "                # detections = detections[np.isin(detections.class_id, selected_classes)]\n",
    "\n",
    "                labels = [f\"{model.model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "                \n",
    "                results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                \n",
    "                if not results.pose_landmarks: continue\n",
    "                \n",
    "                idx = 0\n",
    "                draw_line_dic = {}\n",
    "                \n",
    "                for x_and_y in results.pose_landmarks.landmark:\n",
    "                    if idx in attention_dot:\n",
    "                        xy_list.append(x_and_y.x)\n",
    "                        xy_list.append(x_and_y.y)\n",
    "                        xy_list_flip.append(1 - x_and_y.x)\n",
    "                        xy_list_flip.append(1 - x_and_y.y)\n",
    "                        x, y = int(x_and_y.x * 640), int(x_and_y.y * 640)\n",
    "                        draw_line_dic[idx] = [x, y]\n",
    "                    idx += 1\n",
    "                \n",
    "                if len(detections.xyxy) == 0:\n",
    "                    detected_obj = [0.0, 0.0, 0.0, 0.0]\n",
    "                else:\n",
    "                    detected_obj = list(detections.xyxy[0] / 640)\n",
    "                \n",
    "                detected_obj_flip = list(np.array(detected_obj) * np.array([-1, 1, -1, 1]))\n",
    "\n",
    "                xy_list += detected_obj\n",
    "                xy_list_flip += detected_obj_flip\n",
    "\n",
    "                xy_list_list.append(xy_list)\n",
    "                xy_list_list_flip.append(xy_list_flip)\n",
    "                \n",
    "                for line in draw_line:\n",
    "                    x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "                    x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "                    img = cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "                \n",
    "                img = box_annotator.annotate(\n",
    "                    scene=img, \n",
    "                    detections=detections, \n",
    "                    labels=labels)\n",
    "                \n",
    "                cv2.imshow('Landmark Image', img)\n",
    "                cv2.waitKey(1)\n",
    "            \n",
    "            elif ret == False: break\n",
    "            \n",
    "            cnt += 1\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return xy_list_list + xy_list_list_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton Ï∂îÏ∂ú(Í±¥ÎÑà Îõ∞Í∏∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702254751.093124    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254751.097404    7381 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254763.148030    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254763.150118    7438 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254768.622636    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254768.624075    7475 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254774.578148    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254774.579267    7518 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254781.890489    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254781.891591    7556 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254785.169527    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254785.170477    7591 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254793.355376    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254793.356531    7629 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254799.037456    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254799.038658    7666 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254805.697286    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254805.702504    7703 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254812.198249    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254812.198902    7740 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254819.126033    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254819.127305    7777 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254826.197424    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254826.199309    7815 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254830.334761    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254830.336664    7851 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254848.009025    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254848.010371    7892 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254854.565563    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254854.566942    7932 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254860.999580    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254861.000943    7969 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254867.731556    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254867.732911    8006 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254874.723386    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254874.724846    8044 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254880.943217    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254880.943992    8082 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254897.261235    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254897.261987    8137 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254907.348698    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254907.350085    8177 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254924.833049    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254924.834429    8220 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254931.710161    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254931.711564    8259 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254939.000559    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254939.001827    8297 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254956.482232    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254956.483001    8337 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254973.176274    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254973.177436    8380 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254979.567307    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254979.571102    8419 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254986.102727    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254986.103473    8456 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254992.013638    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254992.014397    8493 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702254997.816423    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702254997.818553    8531 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255003.929589    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255003.930658    8569 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255021.065804    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255021.067328    8610 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255026.122201    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255026.123082    8649 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255031.940132    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255031.940854    8686 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255037.455970    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255037.456651    8723 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255048.717083    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255048.718325    8761 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255052.767653    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255052.769014    8798 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255059.440716    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255059.441525    8836 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255065.549558    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255065.550525    8873 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255074.054904    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255074.056051    8911 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255090.383335    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255090.385077    8951 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255094.027819    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255094.028600    8989 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255102.678984    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255102.679872    9027 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255107.730642    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255107.732103    9065 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255112.988137    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255112.989119    9100 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255116.961786    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255116.962520    9137 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255132.861125    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255132.862604    9178 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255139.278622    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255139.279697    9217 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255149.093203    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255149.094326    9255 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255155.098292    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255155.099792    9371 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255162.613292    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255162.614445    9410 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255167.684141    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255167.685649    9445 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255174.282366    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255174.283239    9482 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255183.186267    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255183.189601    9520 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255200.631130    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255200.632306    9565 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255216.741183    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255216.742430    9607 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255223.524181    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255223.525299    9647 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255228.747097    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255228.748121    9687 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255233.435081    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255233.436725    9723 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255240.873039    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255240.874108    9760 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255245.480841    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255245.481881    9797 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255252.805158    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255252.805891    9834 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255260.738608    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255260.739688    9872 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255268.298485    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255268.299311    9909 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255274.731858    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255274.733028    9946 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255283.496126    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255283.497166    9984 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255289.831743    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255289.833098   10021 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255306.326954    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255306.328983   10063 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255311.535090    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255311.535773   10101 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255326.446420    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255326.447580   10141 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255331.314488    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255331.315327   10178 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255349.230393    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255349.232993   10219 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255352.865824    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255352.866589   10257 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255358.797037    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255358.798265   10294 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255363.735731    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255363.736583   10331 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255369.897150    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255369.898217   10368 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255375.952572    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255375.953235   10406 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255383.115186    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255383.116474   10443 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255390.685787    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255390.686996   10480 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255397.114705    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255397.115484   10517 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255414.099339    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255414.100073   10570 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255423.593183    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255423.594475   10611 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255431.282167    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255431.283231   10649 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255437.823203    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255437.824218   10686 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255446.228626    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255446.229686   10723 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255452.722377    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255452.723337   10760 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255468.517794    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255468.519491   10801 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255474.160344    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255474.161592   10839 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255490.791449    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255490.792419   10880 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255496.545058    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255496.546402   10922 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255504.371083    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255504.372094   10959 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255511.144896    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255511.145737   10996 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255520.048248    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255520.049233   11034 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255526.132984    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255526.133721   11071 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255532.271338    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255532.272079   11108 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255538.909514    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255538.910672   11146 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255555.911392    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255555.912449   11187 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255563.431887    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255563.432863   11226 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255569.755980    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255569.757458   11263 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255577.980597    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255577.981997   11301 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255584.699859    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255584.701074   11338 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255591.110529    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255591.111274   11375 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255597.118328    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255597.119291   11412 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255605.214298    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255605.215050   11450 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255609.286038    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255609.287009   11487 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255618.766907    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255618.768124   11525 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255627.048599    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255627.049378   11563 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255633.132377    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255633.134424   11601 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255642.302418    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255642.303693   11639 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255647.774975    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255647.776312   11676 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255654.381152    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255654.382562   11713 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255662.009364    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255662.010120   11751 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255669.347013    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255669.347740   11788 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255678.111572    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255678.112590   11826 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255693.883221    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255693.884608   11867 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255711.908585    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255711.909334   11910 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255720.457579    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255720.458793   11950 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255725.535283    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255725.537206   11986 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255732.170456    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255732.171353   12024 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255747.822872    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255747.823667   12063 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255764.654713    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255764.656244   12107 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255781.597747    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255781.598964   12149 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255786.030823    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255786.032227   12188 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255793.629855    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255793.631116   12225 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255803.051010    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255803.052078   12263 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255807.881559    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255807.883023   12300 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255817.188647    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255817.189543   12339 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255825.740823    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255825.742230   12377 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255832.787195    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255832.788480   12414 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255840.333000    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255840.333801   12452 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255844.391627    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255844.392859   12488 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255853.385800    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255853.387169   12526 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255869.706936    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255869.707680   12566 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255874.670768    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255874.671559   12605 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255883.343582    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255883.344775   12643 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255890.393770    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255890.394713   12680 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255895.801416    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255895.802669   12717 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255901.256556    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255901.257883   12754 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255908.450880    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255908.452189   12792 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255912.661907    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255912.663635   12829 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255917.889017    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255917.890239   12866 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255924.008904    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255924.009832   12903 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255929.906404    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255929.907396   12940 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255937.881059    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255937.882689   12977 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255942.163566    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255942.164289   13014 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255949.879101    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255949.879928   13051 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255956.222979    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255956.224511   13088 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255964.037501    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255964.038470   13126 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255973.738035    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255973.739210   13164 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255978.234457    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255978.235297   13200 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702255986.917911    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702255986.918935   13238 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256003.474286    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256003.475772   13280 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256019.991283    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256019.992132   13322 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256026.134556    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256026.135458   13362 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256034.893559    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256034.894387   13400 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256051.809789    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256051.811149   13440 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256056.532386    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256056.533280   13479 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256065.132779    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256065.133658   13517 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256072.521687    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256072.522525   13554 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256077.825980    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256077.827472   13591 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256086.559723    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256086.560847   13629 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256093.761728    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256093.764094   13666 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256100.988548    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256100.989873   13704 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256107.128534    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256107.129339   13742 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256113.038307    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256113.039648   13779 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256121.711224    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256121.712655   13817 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256128.292589    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256128.293723   13854 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256136.941068    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256136.942253   13893 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256142.942249    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256142.943889   13931 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256153.102407    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256153.103133   13968 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256160.957923    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256160.958739   14006 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256170.482860    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256170.484405   14044 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256187.722889    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256187.723601   14085 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256192.133365    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256192.134756   14123 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256197.522943    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256197.524163   14160 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256202.962346    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256202.963877   14197 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256207.166967    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256207.167814   14234 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256224.220995    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256224.222506   14276 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256232.925321    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256232.926149   14316 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256239.106448    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256239.107800   14353 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256245.500989    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256245.502280   14390 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256253.156078    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256253.157461   14427 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256259.792858    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256259.794150   14465 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256265.104749    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256265.106255   14501 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256282.271821    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256282.272635   14543 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256287.667586    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256287.668947   14582 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256304.118173    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256304.119547   14623 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256311.537068    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256311.538515   14663 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256316.956567    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256316.957969   14700 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256323.831782    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256323.832596   14738 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256331.942701    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256331.943517   14775 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256336.948363    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256336.949170   14812 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256344.554527    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256344.555640   14849 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256348.015322    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256348.016099   14885 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256355.516640    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256355.518032   14923 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256362.333150    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256362.334635   14960 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256369.987056    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256369.988489   14998 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256379.270266    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256379.271149   15035 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256385.174824    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256385.176345   15072 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256392.330190    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256392.331656   15110 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256408.883479    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256408.885562   15150 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256416.548706    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256416.550160   15190 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256423.153719    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256423.155043   15227 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256430.980261    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256430.981649   15264 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256447.601784    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256447.603286   15305 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256452.921448    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256452.922279   15343 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256469.412657    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256469.413475   15385 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256485.796833    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256485.798515   15427 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256491.231641    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256491.233050   15466 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256495.074399    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256495.075795   15502 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256500.968357    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256500.969433   15540 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256504.870741    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256504.872085   15575 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256511.581003    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256511.583123   15615 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256518.980383    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256518.981166   15652 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256525.842645    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256525.843404   15689 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256532.143116    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256532.143987   15726 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256537.895981    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256537.896817   15763 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256545.023845    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256545.024792   15801 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256561.847876    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256561.849053   15841 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256570.308165    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256570.309432   15881 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256587.032395    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256587.033466   15927 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256595.057071    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256595.058555   15967 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256599.873162    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256599.876779   16003 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256617.102668    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256617.103947   16045 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256624.118797    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256624.119697   16084 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256631.867882    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256631.868758   16122 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256639.306669    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256639.308384   16159 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256644.753228    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256644.754184   16196 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256650.504364    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256650.505120   16233 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256658.634228    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256658.635549   16271 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n",
      "I0000 00:00:1702256668.021792    5365 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702256668.022752   16309 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n",
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# video_path = '../tmp_data/train_data'\n",
    "video_path = '../data/action_data/train_data'\n",
    "video_name_list = os.listdir(video_path)\n",
    "dataset = []\n",
    "length = 50\n",
    "interval = 1\n",
    "\n",
    "for video_name in video_name_list:\n",
    "    if 'nothing' in video_name: \n",
    "        label = 0\n",
    "    elif 'picking_up' in video_name:\n",
    "        label = 1\n",
    "    elif 'putting_down' in video_name: \n",
    "        label = 2\n",
    "    elif 'holding' in video_name:\n",
    "        label = 3\n",
    "    \n",
    "    skel_data = show_skeleton('{}/{}'.format(video_path, video_name), interval, attention_dot, draw_line)\n",
    "    \n",
    "    for idx in range(0, len(skel_data), int(length/2)):\n",
    "        seq_list = skel_data[idx : idx + length]\n",
    "        if len(seq_list) == length:\n",
    "            dataset.append({'key' : label, 'value' : seq_list})\n",
    "\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cuda GPU ÏÑ§Ï†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU is unavailable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list:\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Í∞úÏàò ÌôïÏù∏(Í±¥ÎÑà Îõ∞Í∏∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m split_ratio \u001b[39m=\u001b[39m [\u001b[39m0.8\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_len \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(dataset) \u001b[39m*\u001b[39m split_ratio[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m val_len \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(dataset) \u001b[39m*\u001b[39m split_ratio[\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset) \u001b[39m-\u001b[39m train_len \u001b[39m-\u001b[39m val_len\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "split_ratio = [0.8, 0.1, 0.1]\n",
    "train_len = int(len(dataset) * split_ratio[0])\n",
    "val_len = int(len(dataset) * split_ratio[1])\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_loader, val_loader, test_loader Ï†ÄÏû•!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m MyDataset(dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_data, valid_data, test_data \u001b[39m=\u001b[39m random_split(train_dataset, [train_len, val_len, test_len])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_data, batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(dataset)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = 8)\n",
    "val_loader = DataLoader(valid_data, batch_size = 8)\n",
    "test_loader = DataLoader(test_data, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# DataLoaderÎ•º ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "def save_data_loader(loader, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(loader, f)\n",
    "\n",
    "# Ï†ÄÏû•Îêú DataLoaderÎ•º Î∂àÎü¨Ïò§Í∏∞\n",
    "def load_data_loader(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loader = pickle.load(f)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.MyDataset'>: it's not the same object as __main__.MyDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# DataLoaderÎ•º ÌååÏùºÎ°ú Ï†ÄÏû•\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m save_data_loader(train_loader, \u001b[39m'\u001b[39;49m\u001b[39m../data_loaders/train_loader.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m save_data_loader(val_loader, \u001b[39m'\u001b[39m\u001b[39m../data_loaders/val_loader.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m save_data_loader(test_loader, \u001b[39m'\u001b[39m\u001b[39m../data_loaders/test_loader.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_data_loader\u001b[39m(loader, file_path):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         pickle\u001b[39m.\u001b[39;49mdump(loader, f)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.MyDataset'>: it's not the same object as __main__.MyDataset"
     ]
    }
   ],
   "source": [
    "# DataLoaderÎ•º ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "save_data_loader(train_loader, '../data_loaders/train_loader.pkl')\n",
    "save_data_loader(val_loader, '../data_loaders/val_loader.pkl')\n",
    "save_data_loader(test_loader, '../data_loaders/test_loader.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader Î∂àÎü¨Ïò§Í∏∞!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jun/dev_ws/Projects/DL_Project/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Data shape: torch.Size([8, 50, 32])\n",
      "Target shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Ï†ÄÏû•Îêú DataLoaderÎ•º Î∂àÎü¨Ïò§Í∏∞\n",
    "train_loader = load_data_loader('../data_loaders/train_loader.pkl')\n",
    "val_loader = load_data_loader('../data_loaders/val_loader.pkl')\n",
    "test_loader = load_data_loader('../data_loaders/test_loader.pkl')\n",
    "\n",
    "# ÏòàÏãúÎ°ú Î∂àÎü¨Ïò® DataLoaderÏùò Ï≤´ Î≤àÏß∏ Î∞∞Ïπò ÌôïÏù∏\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"Target shape:\", target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skeleton_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_dim, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(input_dim):\n",
    "    plt.rc('font', size = 10)\n",
    "    global net, loss_fn, optim\n",
    "    net = skeleton_LSTM(input_dim).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr = 0.0001)\n",
    "\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    # Î™®Îì† LogÎ•º Ï¥àÍ∏∞Ìôî\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "\n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log Í∏∞Î°ùÏö©\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # Î¶¨Ïä§Ìä∏ ÏïàÏùò ÎßàÏßÄÎßâ Ïà´ÏûêÎ•º Î∞òÌôò (print_log Ìï®ÏàòÏóêÏÑú ÏÇ¨Ïö©)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def print_log():\n",
    "    # ÌïôÏäµ Ï∂îÏù¥ Ï∂úÎ†•\n",
    "\n",
    "    # ÏÜåÏ£ºÏ†ê 3ÏûêÎ¶¨ ÏàòÍπåÏßÄ Ï°∞Ï†à\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 2)\n",
    "\n",
    "    log_str = 'Epoch: {:3}, | T_Loss {:5}, | T_acc {:5} | V_loss {:5} | V_acc {:5} | time {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "\n",
    "    log_stack.append(log_str) # ÌîÑÎ¶∞Ìä∏ Ï§ÄÎπÑ\n",
    "\n",
    "    # ÌïôÏäµ Ï∂îÏù¥ Í∑∏ÎûòÌîÑ Ï∂úÎ†•\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # Í∑∏ÎûòÌîÑ ÏÇ¨Ïù¥Ï¶à ÏÑ§Ï†ï\n",
    "    hist_fig.patch.set_facecolor('white') # Í∑∏ÎûòÌîÑ Î∞∞Í≤ΩÏÉâ ÏÑ§Ï†ï\n",
    "\n",
    "    # Loss Line Íµ¨ÏÑ±\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "\n",
    "    # Acc. Line Íµ¨ÏÑ±\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "    # Í∑∏ÎûòÌîÑ Ï∂úÎ†•\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line  # ÏúÑÏóêÏÑú ÏÑ†Ïñ∏Ìïú plt Ï†ïÎ≥ºÎì§ ÌÜµÌï©\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines]) # ÏàúÏÑúÎåÄÎ°ú Í∑∏Î†§Ï£ºÍ∏∞\n",
    "    loss_axis.grid()  # Í≤©Ïûê ÏÑ§Ï†ï\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "\n",
    "    # ÌÖçÏä§Ìä∏ Î°úÍ∑∏ Ï∂úÎ†•\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# ÌïôÏäµ ÏïåÍ≥†Î¶¨Ï¶ò\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "\n",
    "    # ÏÇ¨Ïö©ÎêòÎäî Î≥ÄÏàò Ï¥àÍ∏∞Ìôî\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "\n",
    "    # 1 iteration ÌïôÏäµ ÏïåÍ≥†Î¶¨Ï¶ò (forÎ¨∏ÏùÑ ÎÇòÏò§Î©¥ 1 epoch ÏôÑÎ£å)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # 1. Feed-Forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()   # ÌïôÏäµÎïåÎßå Ïì∞Ïù¥Îäî Dropout, Batch NormalizationÏùÑ ÎØ∏ÏÇ¨Ïö©\n",
    "\n",
    "        result = net(data)\n",
    "        _, out = torch.max(result, 1)\n",
    "\n",
    "        # 2. loss Í≥ÑÏÇ∞\n",
    "        loss = loss_fn(result, label)\n",
    "        iter_loss.append(loss.item())  # ÌïôÏäµ Ï∂îÏù¥Î•º ÏúÑÌïòÏó¨ loss Í∏∞Î°ù\n",
    "\n",
    "        # 3. Ïó≠Ï†ÑÌåå ÌïôÏäµ ÌõÑ Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "\n",
    "        # 4. Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label)\n",
    "        iter_acc.append(acc_partial.item())\n",
    "\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "\n",
    "    clear_memory()\n",
    "\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ÏÖã Í∞úÏàò ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jun/dev_ws/Projects/DL_Project/src/new_action_yolo.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(dataset[\u001b[39m10\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(dataset[10]['value'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Trainig Initialization(ÎàÑÎ•¥Í≥† Î∞îÎ°ú Ï§ëÏßÄÌïòÍ≥† ÎÑòÏñ¥Í∞ÄÍ∏∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 990x297 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.108 | V_acc 0.973 | time  1.73\n",
      "Epoch: 299, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.111 | V_acc 0.973 | time  1.75\n",
      "Epoch: 298, | T_Loss 0.001, | T_acc   1.0 | V_loss  0.11 | V_acc 0.973 | time  1.59\n",
      "Epoch: 297, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.108 | V_acc 0.973 | time  1.63\n",
      "Epoch: 296, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.107 | V_acc 0.973 | time  1.65\n",
      "Epoch: 295, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.103 | V_acc 0.973 | time  1.68\n",
      "Epoch: 294, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.104 | V_acc 0.973 | time  1.38\n",
      "Epoch: 293, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.105 | V_acc 0.973 | time  1.53\n",
      "Epoch: 292, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.104 | V_acc 0.973 | time  1.69\n",
      "Epoch: 291, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.106 | V_acc 0.973 | time  1.68\n",
      "Epoch: 290, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.105 | V_acc 0.973 | time  1.67\n",
      "Epoch: 289, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.106 | V_acc 0.973 | time  1.61\n",
      "Epoch: 288, | T_Loss 0.001, | T_acc   1.0 | V_loss 0.107 | V_acc 0.973 | time  1.66\n",
      "Epoch: 287, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.105 | V_acc 0.973 | time  1.59\n",
      "Epoch: 286, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.105 | V_acc 0.973 | time  1.63\n",
      "Epoch: 285, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.105 | V_acc 0.973 | time  1.63\n",
      "Epoch: 284, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.103 | V_acc 0.973 | time  1.78\n",
      "Epoch: 283, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.103 | V_acc 0.973 | time  1.66\n",
      "Epoch: 282, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.103 | V_acc 0.973 | time  1.67\n",
      "Epoch: 281, | T_Loss 0.002, | T_acc   1.0 | V_loss   0.1 | V_acc 0.973 | time  1.58\n",
      "Epoch: 280, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.101 | V_acc 0.973 | time  1.66\n",
      "Epoch: 279, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.098 | V_acc 0.973 | time  1.55\n",
      "Epoch: 278, | T_Loss 0.002, | T_acc   1.0 | V_loss   0.1 | V_acc 0.973 | time  1.74\n",
      "Epoch: 277, | T_Loss 0.002, | T_acc   1.0 | V_loss   0.1 | V_acc 0.973 | time  1.68\n",
      "Epoch: 276, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.099 | V_acc 0.973 | time  1.63\n",
      "Epoch: 275, | T_Loss 0.002, | T_acc   1.0 | V_loss 0.099 | V_acc 0.973 | time  1.62\n",
      "Epoch: 274, | T_Loss 0.003, | T_acc   1.0 | V_loss 0.096 | V_acc 0.973 | time  1.63\n",
      "Epoch: 273, | T_Loss 0.003, | T_acc   1.0 | V_loss 0.095 | V_acc 0.973 | time  1.74\n",
      "Epoch: 272, | T_Loss 0.003, | T_acc   1.0 | V_loss 0.092 | V_acc 0.973 | time  1.69\n",
      "Epoch: 271, | T_Loss 0.003, | T_acc   1.0 | V_loss 0.088 | V_acc 0.973 | time   1.6\n",
      "Epoch: 270, | T_Loss 0.004, | T_acc   1.0 | V_loss 0.084 | V_acc 0.973 | time  1.58\n",
      "Epoch: 269, | T_Loss 0.005, | T_acc   1.0 | V_loss 0.084 | V_acc 0.973 | time  1.49\n",
      "Epoch: 268, | T_Loss  0.01, | T_acc 0.998 | V_loss 0.075 | V_acc 0.973 | time  1.45\n",
      "Epoch: 267, | T_Loss  0.01, | T_acc 0.999 | V_loss 0.129 | V_acc 0.973 | time  1.47\n",
      "Epoch: 266, | T_Loss 0.038, | T_acc 0.991 | V_loss 0.131 | V_acc 0.946 | time  1.54\n",
      "Epoch: 265, | T_Loss 0.041, | T_acc 0.987 | V_loss 0.178 | V_acc 0.946 | time  1.63\n",
      "Epoch: 264, | T_Loss 0.082, | T_acc 0.977 | V_loss 0.106 | V_acc 0.973 | time  1.65\n",
      "Epoch: 263, | T_Loss 0.021, | T_acc 0.995 | V_loss 0.081 | V_acc 0.955 | time  1.65\n",
      "Epoch: 262, | T_Loss 0.005, | T_acc   1.0 | V_loss 0.111 | V_acc 0.946 | time   1.7\n",
      "Epoch: 261, | T_Loss 0.012, | T_acc 0.997 | V_loss 0.153 | V_acc 0.955 | time  1.83\n",
      "Epoch: 260, | T_Loss 0.011, | T_acc 0.998 | V_loss 0.155 | V_acc 0.946 | time  1.64\n",
      "Epoch: 259, | T_Loss 0.037, | T_acc 0.987 | V_loss 0.202 | V_acc 0.938 | time  1.76\n",
      "Epoch: 258, | T_Loss 0.019, | T_acc 0.995 | V_loss 0.107 | V_acc 0.973 | time  1.82\n",
      "Epoch: 257, | T_Loss 0.057, | T_acc 0.981 | V_loss 0.164 | V_acc 0.946 | time  1.71\n",
      "Epoch: 256, | T_Loss 0.059, | T_acc 0.988 | V_loss  0.17 | V_acc 0.973 | time  1.57\n",
      "Epoch: 255, | T_Loss 0.042, | T_acc 0.987 | V_loss 0.233 | V_acc 0.929 | time  1.65\n",
      "Epoch: 254, | T_Loss  0.14, | T_acc 0.951 | V_loss 0.129 | V_acc 0.955 | time  1.57\n",
      "Epoch: 253, | T_Loss 0.025, | T_acc 0.992 | V_loss 0.163 | V_acc 0.955 | time  1.69\n",
      "Epoch: 252, | T_Loss 0.025, | T_acc 0.993 | V_loss  0.09 | V_acc 0.964 | time  1.46\n",
      "Epoch: 251, | T_Loss 0.066, | T_acc  0.98 | V_loss 0.132 | V_acc 0.964 | time  1.69\n",
      "Epoch: 250, | T_Loss 0.022, | T_acc 0.993 | V_loss 0.296 | V_acc  0.92 | time  1.88\n",
      "Epoch: 249, | T_Loss 0.031, | T_acc 0.992 | V_loss 0.068 | V_acc 0.973 | time  1.72\n",
      "Epoch: 248, | T_Loss 0.017, | T_acc 0.997 | V_loss 0.119 | V_acc 0.964 | time  1.74\n",
      "Epoch: 247, | T_Loss 0.021, | T_acc 0.993 | V_loss 0.162 | V_acc 0.955 | time   1.7\n",
      "Epoch: 246, | T_Loss 0.024, | T_acc 0.992 | V_loss 0.098 | V_acc 0.973 | time  1.59\n",
      "Epoch: 245, | T_Loss 0.045, | T_acc 0.985 | V_loss 0.128 | V_acc 0.946 | time  1.53\n",
      "Epoch: 244, | T_Loss 0.061, | T_acc  0.98 | V_loss 0.163 | V_acc  0.94 | time  1.61\n",
      "Epoch: 243, | T_Loss 0.076, | T_acc 0.976 | V_loss 0.132 | V_acc 0.973 | time  1.67\n",
      "Epoch: 242, | T_Loss 0.096, | T_acc 0.969 | V_loss  0.23 | V_acc 0.932 | time  1.62\n",
      "Epoch: 241, | T_Loss  0.09, | T_acc 0.976 | V_loss 0.137 | V_acc 0.946 | time  1.69\n",
      "Epoch: 240, | T_Loss 0.177, | T_acc 0.948 | V_loss 0.175 | V_acc 0.946 | time  1.67\n",
      "Epoch: 239, | T_Loss 0.116, | T_acc  0.97 | V_loss 0.572 | V_acc 0.866 | time  1.89\n",
      "Epoch: 238, | T_Loss 0.016, | T_acc 0.995 | V_loss 0.055 | V_acc 0.973 | time  1.82\n",
      "Epoch: 237, | T_Loss  0.01, | T_acc 0.999 | V_loss 0.075 | V_acc 0.964 | time  1.64\n",
      "Epoch: 236, | T_Loss 0.013, | T_acc 0.995 | V_loss 0.068 | V_acc 0.973 | time  1.72\n",
      "Epoch: 235, | T_Loss 0.018, | T_acc 0.994 | V_loss 0.074 | V_acc 0.973 | time  1.63\n",
      "Epoch: 234, | T_Loss 0.031, | T_acc 0.988 | V_loss 0.127 | V_acc 0.938 | time  1.64\n",
      "Epoch: 233, | T_Loss 0.022, | T_acc 0.995 | V_loss 0.122 | V_acc 0.964 | time  1.58\n",
      "Epoch: 232, | T_Loss 0.034, | T_acc 0.994 | V_loss 0.069 | V_acc 0.973 | time   1.7\n",
      "Epoch: 231, | T_Loss 0.054, | T_acc  0.98 | V_loss 0.077 | V_acc 0.973 | time  1.55\n",
      "Epoch: 230, | T_Loss 0.041, | T_acc 0.992 | V_loss  0.07 | V_acc 0.973 | time  1.56\n",
      "Epoch: 229, | T_Loss 0.054, | T_acc  0.98 | V_loss 0.098 | V_acc 0.964 | time  1.73\n",
      "Epoch: 228, | T_Loss 0.082, | T_acc  0.97 | V_loss 0.073 | V_acc 0.973 | time  1.59\n",
      "Epoch: 227, | T_Loss 0.146, | T_acc 0.954 | V_loss 0.227 | V_acc 0.938 | time  1.69\n",
      "Epoch: 226, | T_Loss 0.265, | T_acc 0.922 | V_loss 0.083 | V_acc 0.964 | time  1.72\n",
      "Epoch: 225, | T_Loss 0.047, | T_acc 0.986 | V_loss 0.165 | V_acc 0.946 | time  1.66\n",
      "Epoch: 224, | T_Loss 0.076, | T_acc 0.972 | V_loss 0.095 | V_acc 0.982 | time  1.75\n",
      "Epoch: 223, | T_Loss 0.198, | T_acc  0.94 | V_loss 0.226 | V_acc 0.929 | time  1.66\n",
      "Epoch: 222, | T_Loss 0.019, | T_acc 0.994 | V_loss 0.216 | V_acc 0.955 | time  1.51\n",
      "Epoch: 221, | T_Loss 0.015, | T_acc 0.995 | V_loss 0.124 | V_acc 0.973 | time  1.73\n",
      "Epoch: 220, | T_Loss 0.016, | T_acc 0.997 | V_loss 0.113 | V_acc 0.982 | time  1.59\n",
      "Epoch: 219, | T_Loss 0.019, | T_acc 0.995 | V_loss 0.116 | V_acc 0.973 | time  1.64\n",
      "Epoch: 218, | T_Loss 0.032, | T_acc 0.992 | V_loss 0.185 | V_acc 0.964 | time  1.68\n",
      "Epoch: 217, | T_Loss  0.02, | T_acc 0.995 | V_loss 0.139 | V_acc 0.973 | time  1.65\n",
      "Epoch: 216, | T_Loss 0.024, | T_acc 0.993 | V_loss 0.151 | V_acc 0.955 | time  1.66\n",
      "Epoch: 215, | T_Loss 0.027, | T_acc 0.995 | V_loss 0.137 | V_acc 0.955 | time  1.52\n",
      "Epoch: 214, | T_Loss 0.109, | T_acc  0.97 | V_loss 0.144 | V_acc 0.955 | time  1.73\n",
      "Epoch: 213, | T_Loss 0.064, | T_acc 0.981 | V_loss 0.301 | V_acc 0.902 | time  1.82\n",
      "Epoch: 212, | T_Loss 0.088, | T_acc 0.975 | V_loss 0.189 | V_acc 0.955 | time  1.63\n",
      "Epoch: 211, | T_Loss 0.024, | T_acc 0.994 | V_loss 0.151 | V_acc 0.964 | time  1.51\n",
      "Epoch: 210, | T_Loss 0.041, | T_acc 0.991 | V_loss 0.147 | V_acc 0.955 | time  1.49\n",
      "Epoch: 209, | T_Loss 0.033, | T_acc 0.991 | V_loss 0.156 | V_acc 0.955 | time  1.74\n",
      "Epoch: 208, | T_Loss 0.044, | T_acc 0.986 | V_loss 0.189 | V_acc 0.946 | time  1.56\n",
      "Epoch: 207, | T_Loss 0.062, | T_acc 0.981 | V_loss 0.207 | V_acc 0.946 | time   1.7\n",
      "Epoch: 206, | T_Loss 0.071, | T_acc 0.976 | V_loss 0.168 | V_acc 0.946 | time  1.71\n",
      "Epoch: 205, | T_Loss 0.095, | T_acc  0.97 | V_loss 0.174 | V_acc 0.929 | time  1.73\n",
      "Epoch: 204, | T_Loss 0.036, | T_acc 0.991 | V_loss  0.16 | V_acc 0.955 | time  1.77\n",
      "Epoch: 203, | T_Loss 0.048, | T_acc 0.988 | V_loss  0.14 | V_acc 0.955 | time  1.73\n",
      "Epoch: 202, | T_Loss 0.061, | T_acc 0.981 | V_loss 0.153 | V_acc 0.973 | time  1.65\n",
      "Epoch: 201, | T_Loss 0.138, | T_acc 0.946 | V_loss 0.203 | V_acc 0.938 | time  1.57\n",
      "Epoch: 200, | T_Loss 0.151, | T_acc 0.948 | V_loss 0.203 | V_acc 0.938 | time  1.62\n",
      "Epoch: 199, | T_Loss 0.124, | T_acc 0.961 | V_loss  0.21 | V_acc 0.955 | time  1.67\n",
      "Epoch: 198, | T_Loss 0.081, | T_acc 0.973 | V_loss  0.25 | V_acc 0.911 | time   1.6\n",
      "Epoch: 197, | T_Loss 0.031, | T_acc 0.993 | V_loss 0.143 | V_acc 0.955 | time  1.57\n",
      "Epoch: 196, | T_Loss 0.042, | T_acc 0.993 | V_loss 0.274 | V_acc  0.92 | time  1.61\n",
      "Epoch: 195, | T_Loss 0.032, | T_acc 0.994 | V_loss 0.126 | V_acc 0.946 | time  1.62\n",
      "Epoch: 194, | T_Loss 0.032, | T_acc 0.992 | V_loss 0.133 | V_acc 0.955 | time  1.67\n",
      "Epoch: 193, | T_Loss 0.029, | T_acc 0.993 | V_loss 0.121 | V_acc 0.946 | time  1.63\n",
      "Epoch: 192, | T_Loss  0.03, | T_acc 0.994 | V_loss 0.132 | V_acc 0.946 | time  1.71\n",
      "Epoch: 191, | T_Loss 0.036, | T_acc 0.992 | V_loss 0.127 | V_acc 0.938 | time   1.6\n",
      "Epoch: 190, | T_Loss 0.064, | T_acc 0.978 | V_loss 0.143 | V_acc  0.92 | time  1.68\n",
      "Epoch: 189, | T_Loss 0.144, | T_acc  0.95 | V_loss  0.17 | V_acc  0.92 | time  1.53\n",
      "Epoch: 188, | T_Loss 0.192, | T_acc 0.939 | V_loss 0.205 | V_acc 0.938 | time  1.59\n",
      "Epoch: 187, | T_Loss 0.143, | T_acc 0.953 | V_loss 0.432 | V_acc 0.884 | time  1.61\n",
      "Epoch: 186, | T_Loss 0.047, | T_acc 0.988 | V_loss 0.155 | V_acc 0.955 | time  1.61\n",
      "Epoch: 185, | T_Loss 0.046, | T_acc  0.99 | V_loss 0.175 | V_acc 0.955 | time  1.68\n",
      "Epoch: 184, | T_Loss 0.051, | T_acc 0.985 | V_loss 0.201 | V_acc 0.938 | time  1.65\n",
      "Epoch: 183, | T_Loss 0.044, | T_acc 0.988 | V_loss 0.201 | V_acc 0.955 | time  1.85\n",
      "Epoch: 182, | T_Loss 0.078, | T_acc 0.976 | V_loss  0.11 | V_acc 0.973 | time  1.69\n",
      "Epoch: 181, | T_Loss 0.072, | T_acc 0.976 | V_loss 0.137 | V_acc 0.964 | time   1.6\n",
      "Epoch: 180, | T_Loss 0.063, | T_acc 0.978 | V_loss 0.207 | V_acc 0.938 | time  1.69\n",
      "Epoch: 179, | T_Loss 0.107, | T_acc 0.965 | V_loss 0.178 | V_acc 0.946 | time  1.68\n",
      "Epoch: 178, | T_Loss 0.083, | T_acc 0.973 | V_loss 0.165 | V_acc 0.964 | time  1.56\n",
      "Epoch: 177, | T_Loss 0.118, | T_acc 0.962 | V_loss 0.157 | V_acc 0.964 | time  1.56\n",
      "Epoch: 176, | T_Loss 0.044, | T_acc 0.988 | V_loss  0.19 | V_acc 0.955 | time  1.64\n",
      "Epoch: 175, | T_Loss 0.062, | T_acc 0.988 | V_loss 0.152 | V_acc 0.964 | time  1.44\n",
      "Epoch: 174, | T_Loss 0.059, | T_acc 0.985 | V_loss 0.182 | V_acc 0.946 | time   1.7\n",
      "Epoch: 173, | T_Loss 0.088, | T_acc  0.97 | V_loss 0.157 | V_acc 0.946 | time  1.44\n",
      "Epoch: 172, | T_Loss 0.087, | T_acc 0.969 | V_loss 0.214 | V_acc 0.955 | time   1.6\n",
      "Epoch: 171, | T_Loss 0.119, | T_acc 0.958 | V_loss 0.218 | V_acc 0.946 | time   1.7\n",
      "Epoch: 170, | T_Loss 0.217, | T_acc 0.926 | V_loss 0.252 | V_acc 0.938 | time  1.66\n",
      "Epoch: 169, | T_Loss  0.23, | T_acc 0.936 | V_loss 0.893 | V_acc 0.726 | time  1.69\n",
      "Epoch: 168, | T_Loss 0.084, | T_acc 0.976 | V_loss 0.132 | V_acc 0.973 | time  1.76\n",
      "Epoch: 167, | T_Loss 0.073, | T_acc 0.973 | V_loss 0.158 | V_acc 0.955 | time  1.49\n",
      "Epoch: 166, | T_Loss 0.056, | T_acc 0.988 | V_loss 0.189 | V_acc 0.955 | time  1.69\n",
      "Epoch: 165, | T_Loss 0.059, | T_acc 0.986 | V_loss 0.176 | V_acc 0.955 | time  1.76\n",
      "Epoch: 164, | T_Loss 0.093, | T_acc 0.977 | V_loss 0.136 | V_acc 0.964 | time  1.47\n",
      "Epoch: 163, | T_Loss 0.092, | T_acc 0.971 | V_loss 0.201 | V_acc 0.955 | time  1.58\n",
      "Epoch: 162, | T_Loss 0.115, | T_acc 0.971 | V_loss 0.143 | V_acc 0.964 | time  1.47\n",
      "Epoch: 161, | T_Loss 0.068, | T_acc  0.98 | V_loss 0.157 | V_acc 0.955 | time  1.64\n",
      "Epoch: 160, | T_Loss 0.076, | T_acc 0.975 | V_loss 0.152 | V_acc 0.964 | time  1.67\n",
      "Epoch: 159, | T_Loss   0.1, | T_acc 0.969 | V_loss 0.222 | V_acc 0.929 | time   1.6\n",
      "Epoch: 158, | T_Loss 0.295, | T_acc 0.894 | V_loss 0.246 | V_acc 0.929 | time  1.58\n",
      "Epoch: 157, | T_Loss 0.121, | T_acc 0.962 | V_loss 0.166 | V_acc 0.964 | time  1.65\n",
      "Epoch: 156, | T_Loss 0.093, | T_acc 0.969 | V_loss 0.149 | V_acc 0.964 | time  1.55\n",
      "Epoch: 155, | T_Loss 0.085, | T_acc 0.979 | V_loss 0.173 | V_acc 0.955 | time  1.77\n",
      "Epoch: 154, | T_Loss 0.102, | T_acc 0.976 | V_loss  0.14 | V_acc 0.946 | time  1.85\n",
      "Epoch: 153, | T_Loss 0.126, | T_acc 0.955 | V_loss 0.233 | V_acc 0.938 | time  1.85\n",
      "Epoch: 152, | T_Loss   0.2, | T_acc 0.935 | V_loss 0.238 | V_acc  0.92 | time  1.64\n",
      "Epoch: 151, | T_Loss  0.12, | T_acc 0.964 | V_loss 0.257 | V_acc  0.92 | time  1.48\n",
      "Epoch: 150, | T_Loss 0.176, | T_acc 0.953 | V_loss 0.202 | V_acc 0.955 | time  1.68\n",
      "Epoch: 149, | T_Loss 0.142, | T_acc 0.963 | V_loss 0.235 | V_acc 0.946 | time  1.74\n",
      "Epoch: 148, | T_Loss 0.113, | T_acc 0.969 | V_loss 0.181 | V_acc 0.946 | time  1.54\n",
      "Epoch: 147, | T_Loss  0.11, | T_acc  0.97 | V_loss 0.154 | V_acc 0.964 | time  1.43\n",
      "Epoch: 146, | T_Loss 0.174, | T_acc 0.954 | V_loss   0.2 | V_acc 0.955 | time  1.68\n",
      "Epoch: 145, | T_Loss 0.121, | T_acc 0.961 | V_loss 0.196 | V_acc 0.955 | time  1.74\n",
      "Epoch: 144, | T_Loss 0.139, | T_acc 0.956 | V_loss 0.192 | V_acc 0.946 | time  1.77\n",
      "Epoch: 143, | T_Loss 0.169, | T_acc 0.954 | V_loss 0.345 | V_acc 0.911 | time  1.47\n",
      "Epoch: 142, | T_Loss 0.183, | T_acc 0.939 | V_loss 0.259 | V_acc 0.938 | time  1.64\n",
      "Epoch: 141, | T_Loss 0.181, | T_acc 0.941 | V_loss 0.353 | V_acc 0.893 | time  1.71\n",
      "Epoch: 140, | T_Loss 0.201, | T_acc 0.939 | V_loss 0.201 | V_acc 0.929 | time  1.67\n",
      "Epoch: 139, | T_Loss 0.183, | T_acc 0.939 | V_loss 0.287 | V_acc 0.929 | time  1.63\n",
      "Epoch: 138, | T_Loss 0.227, | T_acc 0.929 | V_loss 0.312 | V_acc 0.911 | time  1.64\n",
      "Epoch: 137, | T_Loss 0.246, | T_acc 0.917 | V_loss 0.266 | V_acc 0.929 | time  1.64\n",
      "Epoch: 136, | T_Loss 0.167, | T_acc 0.951 | V_loss 0.275 | V_acc 0.902 | time  1.79\n",
      "Epoch: 135, | T_Loss 0.192, | T_acc 0.946 | V_loss 0.205 | V_acc 0.946 | time  1.73\n",
      "Epoch: 134, | T_Loss 0.242, | T_acc 0.925 | V_loss 0.242 | V_acc 0.929 | time  1.68\n",
      "Epoch: 133, | T_Loss  0.24, | T_acc 0.927 | V_loss 0.295 | V_acc  0.92 | time  1.82\n",
      "Epoch: 132, | T_Loss 0.209, | T_acc 0.938 | V_loss 0.303 | V_acc 0.902 | time  1.47\n",
      "Epoch: 131, | T_Loss 0.234, | T_acc 0.927 | V_loss 0.322 | V_acc 0.884 | time  1.58\n",
      "Epoch: 130, | T_Loss 0.223, | T_acc 0.939 | V_loss 0.373 | V_acc 0.902 | time  1.61\n",
      "Epoch: 129, | T_Loss 0.236, | T_acc 0.926 | V_loss 0.392 | V_acc 0.884 | time  1.73\n",
      "Epoch: 128, | T_Loss 0.256, | T_acc 0.916 | V_loss 0.289 | V_acc 0.911 | time  1.64\n",
      "Epoch: 127, | T_Loss 0.234, | T_acc 0.929 | V_loss 0.292 | V_acc 0.893 | time  1.74\n",
      "Epoch: 126, | T_Loss 0.287, | T_acc 0.903 | V_loss 0.261 | V_acc 0.929 | time  1.76\n",
      "Epoch: 125, | T_Loss 0.393, | T_acc 0.875 | V_loss 0.341 | V_acc 0.866 | time   1.7\n",
      "Epoch: 124, | T_Loss  0.34, | T_acc 0.897 | V_loss 0.464 | V_acc 0.824 | time  1.75\n",
      "Epoch: 123, | T_Loss 0.271, | T_acc 0.919 | V_loss 0.375 | V_acc 0.866 | time  1.57\n",
      "Epoch: 122, | T_Loss 0.296, | T_acc 0.905 | V_loss 0.337 | V_acc 0.875 | time  1.69\n",
      "Epoch: 121, | T_Loss 0.319, | T_acc 0.907 | V_loss 0.411 | V_acc 0.848 | time  1.57\n",
      "Epoch: 120, | T_Loss 0.348, | T_acc 0.895 | V_loss 0.333 | V_acc 0.875 | time  1.75\n",
      "Epoch: 119, | T_Loss 0.316, | T_acc 0.906 | V_loss 0.279 | V_acc 0.929 | time   1.7\n",
      "Epoch: 118, | T_Loss 0.345, | T_acc 0.892 | V_loss 0.365 | V_acc 0.884 | time  1.76\n",
      "Epoch: 117, | T_Loss 0.347, | T_acc 0.888 | V_loss 0.405 | V_acc 0.857 | time   1.6\n",
      "Epoch: 116, | T_Loss 0.381, | T_acc 0.877 | V_loss 0.433 | V_acc 0.812 | time  1.66\n",
      "Epoch: 115, | T_Loss 0.418, | T_acc 0.867 | V_loss 0.365 | V_acc 0.857 | time  1.59\n",
      "Epoch: 114, | T_Loss 0.348, | T_acc 0.897 | V_loss 0.342 | V_acc 0.893 | time  1.75\n",
      "Epoch: 113, | T_Loss 0.361, | T_acc 0.889 | V_loss 0.411 | V_acc 0.866 | time  1.72\n",
      "Epoch: 112, | T_Loss 0.384, | T_acc 0.877 | V_loss 0.373 | V_acc 0.875 | time   1.6\n",
      "Epoch: 111, | T_Loss 0.377, | T_acc 0.887 | V_loss 0.415 | V_acc 0.857 | time  1.59\n",
      "Epoch: 110, | T_Loss 0.468, | T_acc 0.858 | V_loss 0.452 | V_acc 0.857 | time  1.64\n",
      "Epoch: 109, | T_Loss 0.422, | T_acc  0.87 | V_loss 0.431 | V_acc 0.875 | time   1.6\n",
      "Epoch: 108, | T_Loss 0.435, | T_acc 0.856 | V_loss 0.425 | V_acc 0.875 | time  1.55\n",
      "Epoch: 107, | T_Loss  0.53, | T_acc 0.814 | V_loss 0.459 | V_acc  0.83 | time  1.81\n",
      "Epoch: 106, | T_Loss 0.472, | T_acc 0.838 | V_loss 0.535 | V_acc 0.848 | time  1.73\n",
      "Epoch: 105, | T_Loss 0.535, | T_acc 0.819 | V_loss 0.457 | V_acc  0.83 | time   1.8\n",
      "Epoch: 104, | T_Loss 0.487, | T_acc 0.832 | V_loss 0.499 | V_acc 0.812 | time  1.75\n",
      "Epoch: 103, | T_Loss 0.562, | T_acc 0.796 | V_loss 0.596 | V_acc 0.812 | time  1.63\n",
      "Epoch: 102, | T_Loss 0.505, | T_acc 0.824 | V_loss 0.472 | V_acc  0.83 | time  1.65\n",
      "Epoch: 101, | T_Loss 0.527, | T_acc 0.823 | V_loss 0.636 | V_acc 0.795 | time  1.75\n",
      "Epoch: 100, | T_Loss 0.557, | T_acc 0.801 | V_loss 0.679 | V_acc 0.786 | time  1.63\n",
      "Epoch:  99, | T_Loss 0.579, | T_acc 0.802 | V_loss 0.552 | V_acc 0.777 | time  1.81\n",
      "Epoch:  98, | T_Loss 0.659, | T_acc 0.771 | V_loss 0.647 | V_acc 0.795 | time  1.51\n",
      "Epoch:  97, | T_Loss 0.608, | T_acc 0.782 | V_loss 0.876 | V_acc 0.521 | time  1.62\n",
      "Epoch:  96, | T_Loss 0.595, | T_acc 0.784 | V_loss 0.632 | V_acc 0.759 | time   1.6\n",
      "Epoch:  95, | T_Loss 0.619, | T_acc 0.795 | V_loss 0.629 | V_acc 0.777 | time  1.65\n",
      "Epoch:  94, | T_Loss 0.653, | T_acc  0.78 | V_loss 0.761 | V_acc 0.768 | time  1.61\n",
      "Epoch:  93, | T_Loss 0.689, | T_acc  0.74 | V_loss  0.79 | V_acc 0.732 | time  1.72\n",
      "Epoch:  92, | T_Loss 0.658, | T_acc 0.751 | V_loss 0.769 | V_acc 0.705 | time  1.66\n",
      "Epoch:  91, | T_Loss 0.712, | T_acc 0.743 | V_loss 0.816 | V_acc 0.705 | time  1.67\n",
      "Epoch:  90, | T_Loss 0.741, | T_acc 0.734 | V_loss  0.82 | V_acc 0.714 | time  1.68\n",
      "Epoch:  89, | T_Loss   0.8, | T_acc 0.707 | V_loss 0.753 | V_acc 0.723 | time  1.71\n",
      "Epoch:  88, | T_Loss 0.825, | T_acc 0.694 | V_loss 0.905 | V_acc  0.67 | time  1.81\n",
      "Epoch:  87, | T_Loss 0.824, | T_acc 0.681 | V_loss 0.888 | V_acc 0.661 | time  1.76\n",
      "Epoch:  86, | T_Loss 0.875, | T_acc 0.667 | V_loss 0.949 | V_acc  0.61 | time  1.66\n",
      "Epoch:  85, | T_Loss 1.028, | T_acc 0.626 | V_loss 0.987 | V_acc 0.601 | time   1.7\n",
      "Epoch:  84, | T_Loss 1.285, | T_acc 0.439 | V_loss 1.207 | V_acc  0.61 | time  1.64\n",
      "Epoch:  83, | T_Loss 1.312, | T_acc 0.377 | V_loss 1.352 | V_acc  0.39 | time  1.78\n",
      "Epoch:  82, | T_Loss 1.523, | T_acc 0.314 | V_loss 1.355 | V_acc  0.39 | time  1.74\n",
      "Epoch:  81, | T_Loss 0.968, | T_acc 0.648 | V_loss 2.129 | V_acc 0.238 | time  1.64\n",
      "Epoch:  80, | T_Loss 0.896, | T_acc 0.656 | V_loss 0.983 | V_acc  0.61 | time  1.68\n",
      "Epoch:  79, | T_Loss 0.884, | T_acc 0.662 | V_loss 1.003 | V_acc 0.619 | time  1.66\n",
      "Epoch:  78, | T_Loss 0.938, | T_acc 0.646 | V_loss 1.018 | V_acc 0.583 | time  1.74\n",
      "Epoch:  77, | T_Loss  0.98, | T_acc 0.631 | V_loss 1.028 | V_acc 0.574 | time  1.69\n",
      "Epoch:  76, | T_Loss 1.062, | T_acc 0.596 | V_loss 1.083 | V_acc 0.557 | time  1.55\n",
      "Epoch:  75, | T_Loss 1.126, | T_acc 0.586 | V_loss 1.143 | V_acc 0.539 | time  1.76\n",
      "Epoch:  74, | T_Loss 1.255, | T_acc 0.457 | V_loss 1.249 | V_acc 0.485 | time  1.67\n",
      "Epoch:  73, | T_Loss 1.279, | T_acc 0.417 | V_loss 1.297 | V_acc  0.44 | time  1.83\n",
      "Epoch:  72, | T_Loss 1.287, | T_acc 0.409 | V_loss 1.316 | V_acc 0.423 | time  1.85\n",
      "Epoch:  71, | T_Loss 1.292, | T_acc 0.432 | V_loss 1.307 | V_acc 0.423 | time  1.85\n",
      "Epoch:  70, | T_Loss 1.115, | T_acc 0.593 | V_loss 1.153 | V_acc 0.565 | time  1.53\n",
      "Epoch:  69, | T_Loss 1.139, | T_acc 0.579 | V_loss  1.14 | V_acc 0.565 | time  1.58\n",
      "Epoch:  68, | T_Loss 1.219, | T_acc 0.553 | V_loss 1.196 | V_acc 0.583 | time  1.69\n",
      "Epoch:  67, | T_Loss 1.301, | T_acc  0.38 | V_loss 1.334 | V_acc  0.39 | time  1.71\n",
      "Epoch:  66, | T_Loss 1.333, | T_acc 0.392 | V_loss 1.345 | V_acc  0.39 | time  1.66\n",
      "Epoch:  65, | T_Loss 1.228, | T_acc   0.5 | V_loss 1.261 | V_acc 0.426 | time  1.73\n",
      "Epoch:  64, | T_Loss 1.301, | T_acc 0.382 | V_loss 1.325 | V_acc 0.426 | time  1.66\n",
      "Epoch:  63, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.85\n",
      "Epoch:  62, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.82\n",
      "Epoch:  61, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.351 | V_acc  0.39 | time  1.64\n",
      "Epoch:  60, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.59\n",
      "Epoch:  59, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.61\n",
      "Epoch:  58, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time   1.4\n",
      "Epoch:  57, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.48\n",
      "Epoch:  56, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.68\n",
      "Epoch:  55, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.68\n",
      "Epoch:  54, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.65\n",
      "Epoch:  53, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.63\n",
      "Epoch:  52, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time   1.5\n",
      "Epoch:  51, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time   1.6\n",
      "Epoch:  50, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.88\n",
      "Epoch:  49, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.73\n",
      "Epoch:  48, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.353 | V_acc  0.39 | time  1.82\n",
      "Epoch:  47, | T_Loss 1.306, | T_acc 0.363 | V_loss 1.354 | V_acc  0.39 | time  1.67\n",
      "Epoch:  46, | T_Loss 1.286, | T_acc 0.383 | V_loss 1.362 | V_acc 0.238 | time  1.76\n",
      "Epoch:  45, | T_Loss 1.302, | T_acc  0.38 | V_loss 1.338 | V_acc  0.39 | time  1.59\n",
      "Epoch:  44, | T_Loss 1.303, | T_acc  0.38 | V_loss  1.35 | V_acc  0.39 | time  1.48\n",
      "Epoch:  43, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.59\n",
      "Epoch:  42, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.48\n",
      "Epoch:  41, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.66\n",
      "Epoch:  40, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.65\n",
      "Epoch:  39, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.64\n",
      "Epoch:  38, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.55\n",
      "Epoch:  37, | T_Loss 1.306, | T_acc 0.372 | V_loss 1.353 | V_acc  0.39 | time  1.72\n",
      "Epoch:  36, | T_Loss 1.291, | T_acc 0.378 | V_loss  1.36 | V_acc 0.238 | time  1.72\n",
      "Epoch:  35, | T_Loss 1.305, | T_acc 0.383 | V_loss 1.352 | V_acc  0.39 | time  1.57\n",
      "Epoch:  34, | T_Loss 1.297, | T_acc 0.406 | V_loss 1.361 | V_acc 0.238 | time  1.46\n",
      "Epoch:  33, | T_Loss 1.301, | T_acc 0.394 | V_loss 1.345 | V_acc  0.39 | time  1.52\n",
      "Epoch:  32, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.77\n",
      "Epoch:  31, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.65\n",
      "Epoch:  30, | T_Loss 1.304, | T_acc 0.382 | V_loss 1.352 | V_acc  0.39 | time  1.72\n",
      "Epoch:  29, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.57\n",
      "Epoch:  28, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.58\n",
      "Epoch:  27, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time   1.7\n",
      "Epoch:  26, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.73\n",
      "Epoch:  25, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.66\n",
      "Epoch:  24, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.58\n",
      "Epoch:  23, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time   1.6\n",
      "Epoch:  22, | T_Loss 1.303, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.65\n",
      "Epoch:  21, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.64\n",
      "Epoch:  20, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.63\n",
      "Epoch:  19, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.57\n",
      "Epoch:  18, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.37\n",
      "Epoch:  17, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.73\n",
      "Epoch:  16, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time   1.7\n",
      "Epoch:  15, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.78\n",
      "Epoch:  14, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.54\n",
      "Epoch:  13, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.68\n",
      "Epoch:  12, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.62\n",
      "Epoch:  11, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.353 | V_acc  0.39 | time  1.61\n",
      "Epoch:  10, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.64\n",
      "Epoch:   9, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.353 | V_acc  0.39 | time  1.79\n",
      "Epoch:   8, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.353 | V_acc  0.39 | time  1.56\n",
      "Epoch:   7, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.353 | V_acc  0.39 | time  1.77\n",
      "Epoch:   6, | T_Loss 1.294, | T_acc 0.413 | V_loss 1.342 | V_acc  0.39 | time  1.51\n",
      "Epoch:   5, | T_Loss 1.304, | T_acc  0.38 | V_loss 1.351 | V_acc  0.39 | time  1.68\n",
      "Epoch:   4, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.352 | V_acc  0.39 | time  1.62\n",
      "Epoch:   3, | T_Loss 1.305, | T_acc  0.38 | V_loss 1.351 | V_acc  0.39 | time  1.77\n",
      "Epoch:   2, | T_Loss 1.307, | T_acc  0.38 | V_loss 1.351 | V_acc  0.39 | time  1.74\n",
      "Epoch:   1, | T_Loss 1.352, | T_acc 0.287 | V_loss 1.348 | V_acc  0.39 | time   2.0\n",
      "\n",
      " Training Completed\n"
     ]
    }
   ],
   "source": [
    "# input_dim = len(dataset[0]['value'][0])\n",
    "input_dim = 32\n",
    "init_model(input_dim)\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = 300\n",
    "min_eval_loss = 99999999 # loss Í∞±Ïã† Ïó¨Î∂Ä ÌÉêÏÉâÌïòÍ∏∞ ÏúÑÌïú Î≥ÄÏàò\n",
    "\n",
    "def epoch_not_finished():\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "# Training Iteration\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "    \n",
    "    # vlossÍ∞Ä ÏûëÏïÑÏßà Îïå ÎßàÎã§ pt ÌååÏùº Í∞±Ïã†\n",
    "    if vloss < min_eval_loss:\n",
    "        min_eval_loss = vloss\n",
    "        torch.save(net, '../checkpoint/action_pt/best_action.pt')       \n",
    "print('\\n Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc. : 0.9643\n",
      "Test Loss : 0.2039\n"
     ]
    }
   ],
   "source": [
    "# Ï†ïÌôïÎèÑ Í≤ÄÏ¶ù\n",
    "# Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "net = torch.load('../checkpoint/action_pt/best_action.pt')\n",
    "# net.load_state_dict(checkpoint['model'])\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode = 'test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc. : {}'.format(test_acc))\n",
    "    print('Test Loss : {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÄÏû•Îêú frameÏùò Í∞úÏàò : 1368\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "interval = 1\n",
    "length = 50\n",
    "video_path = '../data/action_data/test_data/test_data_5.MOV'\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "img_list = []\n",
    "\n",
    "if cap.isOpened():\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            img = cv2.resize(img, (640, 640))\n",
    "            if cnt == interval:\n",
    "                img_list.append(img)\n",
    "                cnt = 0\n",
    "            # cv2.imshow(video_name, img)\n",
    "            cv2.waitKey(1)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Ï†ÄÏû•Îêú frameÏùò Í∞úÏàò : {}'.format(len(img_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator(\n",
    "        thickness=2,\n",
    "        text_thickness=2,\n",
    "        text_scale=1)\n",
    "\n",
    "model = YOLO('../checkpoint/yolo_pt/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏàòÏ†ïÎêú ÏΩîÎìú(ÏïÑÎûò ÏõêÎ≥∏ ÏΩîÎìú ÎåÄÏã† Ïù¥Í±∞ ÏÇ¨Ïö©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_centers(results):\n",
    "    # img = img_list[0]\n",
    "    # pose = mp_pose.Pose(static_image_mode=True, model_complexity=1,\n",
    "    #                     enable_segmentation = False, min_detection_confidence=0.3)\n",
    "\n",
    "    # results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    rh_x_sum, rh_y_sum, lh_x_sum, lh_y_sum = 0, 0, 0, 0\n",
    "\n",
    "    hand_centers = []\n",
    "\n",
    "    for k in range(15, 23):\n",
    "        if k == 15 or k == 17 or k == 19 or k == 21:\n",
    "        # if k == 15:\n",
    "            lh_x_sum += results.pose_landmarks.landmark[k].x\n",
    "            lh_y_sum += results.pose_landmarks.landmark[k].y\n",
    "        \n",
    "        \n",
    "        elif k == 16 or k == 18 or k == 20 or k == 22:\n",
    "        # elif k == 16:\n",
    "            rh_x_sum += results.pose_landmarks.landmark[k].x\n",
    "            rh_y_sum += results.pose_landmarks.landmark[k].y\n",
    "            \n",
    "    lh_x_avg, lh_y_avg = lh_x_sum/4, lh_y_sum/4\n",
    "    rh_x_avg, rh_y_avg = rh_x_sum/4, rh_y_sum/4     \n",
    "        \n",
    "    hand_centers.append([lh_x_avg, lh_y_avg])\n",
    "    hand_centers.append([rh_x_avg, rh_y_avg])\n",
    "    \n",
    "    # print(hand_centers)\n",
    "    return hand_centers\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îëê Ï†ê ÏÇ¨Ïù¥Ïùò Ïú†ÌÅ¥Î¶¨ÎîîÏñ∏ Í±∞Î¶¨Î•º Í≥ÑÏÇ∞ÌïòÎäî Ìï®Ïàò\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÌÖåÏù¥Î∏î ÏòÅÏó≠Ïùò xmin, ymin, xmax, ymax Ï¢åÌëú ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 üöÄ Python-3.8.10 torch-2.1.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7765MiB)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.125, 0.8578125)\n",
      "(0.678125, 0.996875)\n"
     ]
    }
   ],
   "source": [
    "# TableÏùò xyxy Ï¢åÌëúÎ•º ÌôïÏù∏Ìï¥Î≥¥Ïûê.\n",
    "import cv2\n",
    "\n",
    "img = img_list[0]\n",
    "img = cv2.flip(img, 0)\n",
    "img = cv2.flip(img, 1)\n",
    "\n",
    "# Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ YOLO Í≤∞Í≥ºÎ•º Í∞ÄÏ†∏Ïò§Îäî Î∂ÄÎ∂ÑÏûÖÎãàÎã§. Î™®Îç∏Ïù¥ Ïñ¥ÎñªÍ≤å Ï†ïÏùòÎêòÏóàÎäîÏßÄÏóê Îî∞Îùº ÏàòÏ†ïÏù¥ ÌïÑÏöîÌï† Ïàò ÏûàÏäµÎãàÎã§.\n",
    "yolo_result = model(img, agnostic_nms=True)[0]\n",
    "\n",
    "# YOLO Í≤∞Í≥ºÎ•º Í∏∞Î∞òÏúºÎ°ú Detections Í∞ùÏ≤¥Î•º ÎßåÎìúÎäî Î∂ÄÎ∂ÑÏûÖÎãàÎã§. Ïù¥ ÏΩîÎìúÎäî ÏÇ¨Ïö© Ï§ëÏù∏ ÎùºÏù¥Î∏åÎü¨Î¶¨Ïóê Îî∞Îùº Îã§Î•º Ïàò ÏûàÏäµÎãàÎã§.\n",
    "detections = sv.Detections.from_yolov8(yolo_result)\n",
    "selected_classes = [4]  # 4: table \n",
    "detections = detections[np.isin(detections.class_id, selected_classes)]\n",
    "labels = [f\"{model.model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "img = box_annotator.annotate(\n",
    "                    scene=img, \n",
    "                    detections=detections, \n",
    "                    labels=labels)\n",
    "\n",
    "for i in range(len(detections.xyxy)):\n",
    "    point_1 = (detections.xyxy[i][0]/640, detections.xyxy[i][2]/640)\n",
    "    point_2 = (detections.xyxy[i][1]/640, detections.xyxy[i][3]/640) \n",
    "print(point_1)\n",
    "print(point_2)\n",
    "\n",
    "cv2.imshow('Annotated Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Ï∂îÎ°† Î∞è ÏãúÌÄÄÏä§ Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702282628.443797   11516 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702282628.444751   11828 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: AMD RENOIR (DRM 3.42.0, 5.15.0-89-generic, LLVM 12.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1368/1368 [01:51<00:00, 12.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "net.eval()\n",
    "out_img_list = []\n",
    "dataset = []\n",
    "status = ''\n",
    "action = 0\n",
    "fruit_type = 5\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1,\n",
    "                    enable_segmentation = False, min_detection_confidence=0.3)\n",
    "\n",
    "print(\"ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...\")\n",
    "\n",
    "xy_list_list = []\n",
    "# file_path = '../log/test5.json'\n",
    "seq = {}\n",
    "seq_index = 0\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "    img = cv2.flip(img, 0)\n",
    "    img = cv2.flip(img, 1)\n",
    "    results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    if not results.pose_landmarks: continue\n",
    "    test_dict = {}\n",
    "    xy_list = []\n",
    "    idx = 0\n",
    "    person = 0\n",
    "    \n",
    "    fruit_quantity = 0\n",
    "    draw_line_dic = {}\n",
    "    \n",
    "    yolo_result = model(img, agnostic_nms=True)[0]\n",
    "    hand_centers = get_hand_centers(results)\n",
    "    \n",
    "    detections = sv.Detections.from_yolov8(yolo_result)\n",
    "    # selected_classes = [0, 1, 2, 3, 4]  # 46: banana, 47 : apple, 49: orange \n",
    "    # detections = detections[np.isin(detections.class_id, selected_classes)]\n",
    "    \n",
    "    if 3 in detections.class_id:\n",
    "        person = 1\n",
    "        \n",
    "    labels = [f\"{model.model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "    \n",
    "    \n",
    "    object_centers = []\n",
    "    class_ids = []\n",
    "    \n",
    "    # if len(detections.xyxy) == 0:\n",
    "    #     detected_obj = [0.0, 0.0, 0.0, 0.0]\n",
    "    # else:\n",
    "    #     detected_obj = list(detections.xyxy[0] / 640)\n",
    "    \n",
    "    for i in range(len(detections.xyxy)):\n",
    "        x_center = ((detections.xyxy[i][0] + detections.xyxy[i][2]) / 2) / 640\n",
    "        y_center = ((detections.xyxy[i][1] + detections.xyxy[i][3]) / 2) / 640\n",
    "        object_centers.append((x_center, y_center))\n",
    "        class_ids.append(detections.class_id[i])\n",
    "    \n",
    "    \n",
    "    min_distance = 100000\n",
    "    holding_object = ''\n",
    "    dist_list = []\n",
    "    \n",
    "    # Ïú†ÌÅ¥Î¶¨ÎîîÏñ∏ Í±∞Î¶¨ Í≥ÑÏÇ∞ Î∞è ÏµúÏÜå Í±∞Î¶¨ÏôÄ Ìï¥Îãπ Î¨ºÏ≤¥ Ïù¥Î¶Ñ Ï∂úÎ†•\n",
    "    for i in range(len(detections.xyxy)):    \n",
    "        \n",
    "        # Holding left hand\n",
    "        if hand_centers[0][1] <= 0.5 and object_centers[i][1] <= 0.8 and (class_ids[i] not in [3, 4]):\n",
    "            distance = calculate_distance(object_centers[i], hand_centers[0])        \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                fruit_type = class_ids[i]\n",
    "                holding_object = model.model.names[class_ids[i]]\n",
    "                fruit_quantity = 1\n",
    "                \n",
    "        # Holding right hand\n",
    "        if hand_centers[1][1] <= 0.5 and object_centers[i][1] <= 0.8 and (class_ids[i] not in [3, 4]):\n",
    "            distance = calculate_distance(object_centers[i], hand_centers[1])        \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                fruit_type = class_ids[i]\n",
    "                holding_object = model.model.names[class_ids[i]]\n",
    "                fruit_quantity = 1\n",
    "        \n",
    "        # if hand_centers[0][1] <= 0.5 and object_centers[i][1] <= 0.8 and class_ids[i] not in [3, 4]:\n",
    "        #         holding_object = model.model.names[class_ids[i]]\n",
    "        \n",
    "        \n",
    "        # if hand_centers[1][1] <= 0.5 and object_centers[i][1] <= 0.8 and class_ids[i] not in [3, 4]:\n",
    "        #         holding_object = model.model.names[class_ids[i]]\n",
    " \n",
    "    min_distance = round(min_distance, 3)\n",
    "    for x_and_y in results.pose_landmarks.landmark:\n",
    "        if idx in attention_dot:\n",
    "            xy_list.append(x_and_y.x)\n",
    "            xy_list.append(x_and_y.y)\n",
    "            x, y = int(x_and_y.x * 640), int(x_and_y.y * 640)\n",
    "            draw_line_dic[idx] = [x, y]\n",
    "        idx += 1\n",
    "    \n",
    "    if len(detections.xyxy) == 0:\n",
    "        detected_obj = [0.0, 0.0, 0.0, 0.0]\n",
    "    else:\n",
    "        detected_obj = list(detections.xyxy[0] / 640)\n",
    "    \n",
    "    xy_list += detected_obj\n",
    "    xy_list_list.append(xy_list)\n",
    "    \n",
    "    for line in draw_line:\n",
    "        x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "        x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "        img = cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "\n",
    "    img = box_annotator.annotate(\n",
    "                    scene=img, \n",
    "                    detections=detections, \n",
    "                    labels=labels\n",
    "                )\n",
    "    if len(xy_list_list) == length:\n",
    "        dataset = []\n",
    "        dataset.append({'key' : 0, 'value' : xy_list_list})\n",
    "        dataset = MyDataset(dataset)\n",
    "        dataset = DataLoader(dataset)\n",
    "        xy_list_list = []\n",
    "        for data, label in dataset:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                result = net(data)\n",
    "                _, output = torch.max(result, 1)\n",
    "                if output.item() == 0:\n",
    "                    # status = f'Nothing {holding_object}, min_dist: {min_distance}'\n",
    "                    status = 'Nothing' \n",
    "                    fruit_type = 5\n",
    "                    action = 0\n",
    "\n",
    "                elif output.item() == 1:  \n",
    "                    status = 'Picking_up'\n",
    "                    fruit_type = 5\n",
    "                    action = 1\n",
    "                    \n",
    "                elif output.item() == 2:\n",
    "                    status = 'Putting_down'\n",
    "                    fruit_type = 5\n",
    "                    action = 2\n",
    "                elif output.item() == 3:\n",
    "                    # if holding_object != '':\n",
    "                    #     # status = f'Holding {holding_object}, min_dist: {min_distance}'\n",
    "                    #     status = f'Holding {holding_object}'\n",
    "                    # else: \n",
    "                    #     status = 'Holding'\n",
    "                    \n",
    "                    status = 'Holding ' + holding_object \n",
    "                    action = 3\n",
    "\n",
    "    # Î≥¥Ï†ï ÏôÑÎ£å: person, action, fruit_type, fruit_quantity\n",
    "    test_dict['person'] = int(person)\n",
    "    test_dict['action'] = int(action)\n",
    "    test_dict['fruit_type'] = int(fruit_type)\n",
    "    test_dict['fruit_quantity'] = int(fruit_quantity)\n",
    "    # print(test_dict)\n",
    "    \n",
    "    # cv2.putText(img, status, (0, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 2)\n",
    "    cv2.putText(img, f'{status}', (0, 25), cv2.FONT_HERSHEY_COMPLEX, 1.0, (0, 0, 0), 1)\n",
    "    out_img_list.append(img)\n",
    "    seq[seq_index] = test_dict\n",
    "    seq_index += 1\n",
    "    \n",
    "with open('../log/action_5_log.json', 'w') as f:\n",
    "     json.dump(seq, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏõêÎ≥∏ ÏΩîÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701060241.301410   14070 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1701060241.302118   15093 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "  0%|          | 1/1028 [00:00<01:54,  8.96it/s]\n",
      "0: 640x640 1 person, 1 tie, 1 dining table, 29.7ms\n",
      "Speed: 0.6ms pre-process, 29.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 toothbrush, 29.9ms\n",
      "Speed: 0.5ms pre-process, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  0%|          | 3/1028 [00:00<01:33, 11.01it/s]\n",
      "0: 640x640 1 person, 1 tie, 3 apples, 29.5ms\n",
      "Speed: 0.5ms pre-process, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  1%|          | 6/1028 [00:00<01:10, 14.44it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 29.6ms\n",
      "Speed: 0.5ms pre-process, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 persons, 3 apples, 1 dining table, 29.6ms\n",
      "Speed: 0.6ms pre-process, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  1%|          | 8/1028 [00:00<01:15, 13.43it/s]\n",
      "0: 640x640 1 person, 1 handbag, 1 dining table, 1 vase, 29.5ms\n",
      "Speed: 0.5ms pre-process, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 dining table, 1 book, 1 vase, 29.5ms\n",
      "Speed: 0.6ms pre-process, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  1%|          | 10/1028 [00:00<01:17, 13.17it/s]\n",
      "0: 640x640 1 person, 3 apples, 29.0ms\n",
      "Speed: 1.0ms pre-process, 29.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 dining table, 26.3ms\n",
      "Speed: 0.5ms pre-process, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  1%|          | 12/1028 [00:00<01:17, 13.06it/s]\n",
      "0: 640x640 1 person, 3 apples, 25.3ms\n",
      "Speed: 0.6ms pre-process, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 dining table, 25.7ms\n",
      "Speed: 0.6ms pre-process, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  1%|‚ñè         | 14/1028 [00:01<01:16, 13.21it/s]\n",
      "0: 640x640 1 person, 1 dining table, 25.3ms\n",
      "Speed: 0.5ms pre-process, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 backpack, 25.7ms\n",
      "Speed: 0.5ms pre-process, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  2%|‚ñè         | 16/1028 [00:01<01:16, 13.22it/s]\n",
      "0: 640x640 1 person, 1 apple, 25.1ms\n",
      "Speed: 0.6ms pre-process, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 apple, 1 dining table, 1 vase, 25.2ms\n",
      "Speed: 1.0ms pre-process, 25.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  2%|‚ñè         | 18/1028 [00:01<01:16, 13.18it/s]\n",
      "0: 640x640 1 person, 1 apple, 25.7ms\n",
      "Speed: 0.6ms pre-process, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 24.6ms\n",
      "Speed: 0.4ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  2%|‚ñè         | 20/1028 [00:01<01:16, 13.22it/s]\n",
      "0: 640x640 1 person, 1 dining table, 24.8ms\n",
      "Speed: 0.7ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 backpack, 24.4ms\n",
      "Speed: 0.4ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  2%|‚ñè         | 22/1028 [00:01<01:15, 13.24it/s]\n",
      "0: 640x640 1 person, 1 apple, 24.5ms\n",
      "Speed: 0.8ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 apple, 1 dining table, 1 book, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  2%|‚ñè         | 24/1028 [00:01<01:15, 13.31it/s]\n",
      "0: 640x640 1 person, 1 apple, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  3%|‚ñé         | 26/1028 [00:01<01:14, 13.37it/s]\n",
      "0: 640x640 1 person, 1 handbag, 3 apples, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  3%|‚ñé         | 28/1028 [00:02<01:15, 13.30it/s]\n",
      "0: 640x640 1 person, 1 kite, 3 apples, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 handbag, 3 apples, 24.3ms\n",
      "Speed: 1.1ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  3%|‚ñé         | 30/1028 [00:02<01:15, 13.29it/s]\n",
      "0: 640x640 1 person, 3 apples, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  3%|‚ñé         | 32/1028 [00:02<01:14, 13.35it/s]\n",
      "0: 640x640 1 person, 3 apples, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 kite, 3 apples, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  3%|‚ñé         | 34/1028 [00:02<01:13, 13.45it/s]\n",
      "0: 640x640 1 person, 1 kite, 2 apples, 1 vase, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 vase, 24.4ms\n",
      "Speed: 0.7ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  4%|‚ñé         | 36/1028 [00:02<01:15, 13.17it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 vase, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 vase, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  4%|‚ñé         | 38/1028 [00:02<01:14, 13.28it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 clock, 1 vase, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 24.3ms\n",
      "Speed: 1.0ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  4%|‚ñç         | 40/1028 [00:03<01:14, 13.32it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 clock, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  4%|‚ñç         | 42/1028 [00:03<01:13, 13.40it/s]\n",
      "0: 640x640 1 person, 1 surfboard, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 25.4ms\n",
      "Speed: 0.5ms pre-process, 25.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  4%|‚ñç         | 44/1028 [00:03<01:13, 13.33it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  4%|‚ñç         | 46/1028 [00:03<01:13, 13.40it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  5%|‚ñç         | 48/1028 [00:03<01:13, 13.40it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.4ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  5%|‚ñç         | 50/1028 [00:03<01:12, 13.43it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.8ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  5%|‚ñå         | 52/1028 [00:03<01:12, 13.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  5%|‚ñå         | 54/1028 [00:04<01:12, 13.36it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 1.0ms pre-process, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.5ms pre-process, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  5%|‚ñå         | 56/1028 [00:04<01:12, 13.48it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.5ms pre-process, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.4ms pre-process, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  6%|‚ñå         | 58/1028 [00:04<01:12, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.6ms pre-process, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  6%|‚ñå         | 60/1028 [00:04<01:11, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  6%|‚ñå         | 62/1028 [00:04<01:11, 13.56it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.4ms pre-process, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  6%|‚ñå         | 64/1028 [00:04<01:10, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.5ms pre-process, 23.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  6%|‚ñã         | 66/1028 [00:04<01:10, 13.71it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.4ms pre-process, 23.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  7%|‚ñã         | 68/1028 [00:05<01:10, 13.69it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.5ms pre-process, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.6ms pre-process, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  7%|‚ñã         | 70/1028 [00:05<01:10, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.4ms pre-process, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  7%|‚ñã         | 72/1028 [00:05<01:10, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.6ms pre-process, 23.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  7%|‚ñã         | 74/1028 [00:05<01:10, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.4ms pre-process, 23.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  7%|‚ñã         | 76/1028 [00:05<01:10, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.5ms pre-process, 23.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  8%|‚ñä         | 78/1028 [00:05<01:09, 13.61it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.7ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  8%|‚ñä         | 80/1028 [00:05<01:09, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  8%|‚ñä         | 82/1028 [00:06<01:09, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  8%|‚ñä         | 84/1028 [00:06<01:09, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  8%|‚ñä         | 86/1028 [00:06<01:10, 13.45it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  9%|‚ñä         | 88/1028 [00:06<01:10, 13.39it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  9%|‚ñâ         | 90/1028 [00:06<01:11, 13.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 cup, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  9%|‚ñâ         | 92/1028 [00:06<01:11, 13.17it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  9%|‚ñâ         | 94/1028 [00:07<01:10, 13.18it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "  9%|‚ñâ         | 96/1028 [00:07<01:10, 13.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 10%|‚ñâ         | 98/1028 [00:07<01:10, 13.20it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 10%|‚ñâ         | 100/1028 [00:07<01:10, 13.15it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 10%|‚ñâ         | 102/1028 [00:07<01:09, 13.25it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 10%|‚ñà         | 104/1028 [00:07<01:10, 13.09it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 10%|‚ñà         | 106/1028 [00:07<01:09, 13.23it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 11%|‚ñà         | 108/1028 [00:08<01:09, 13.32it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 11%|‚ñà         | 110/1028 [00:08<01:08, 13.38it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 11%|‚ñà         | 112/1028 [00:08<01:08, 13.37it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 11%|‚ñà         | 114/1028 [00:08<01:08, 13.35it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 11%|‚ñà‚ñè        | 116/1028 [00:08<01:08, 13.29it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.4ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 11%|‚ñà‚ñè        | 118/1028 [00:08<01:09, 13.16it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.6ms pre-process, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 12%|‚ñà‚ñè        | 120/1028 [00:09<01:08, 13.20it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.7ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 12%|‚ñà‚ñè        | 122/1028 [00:09<01:10, 12.93it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.8ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 12%|‚ñà‚ñè        | 124/1028 [00:09<01:09, 13.05it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 12%|‚ñà‚ñè        | 126/1028 [00:09<01:10, 12.84it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.3ms\n",
      "Speed: 0.4ms pre-process, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.9ms pre-process, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 12%|‚ñà‚ñè        | 128/1028 [00:09<01:10, 12.79it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.6ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.4ms\n",
      "Speed: 0.5ms pre-process, 25.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 13%|‚ñà‚ñé        | 130/1028 [00:09<01:10, 12.69it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.6ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.0ms\n",
      "Speed: 0.5ms pre-process, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 13%|‚ñà‚ñé        | 132/1028 [00:09<01:09, 12.88it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 13%|‚ñà‚ñé        | 134/1028 [00:10<01:09, 12.95it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 13%|‚ñà‚ñé        | 136/1028 [00:10<01:07, 13.15it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 13%|‚ñà‚ñé        | 138/1028 [00:10<01:06, 13.31it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 14%|‚ñà‚ñé        | 140/1028 [00:10<01:07, 13.25it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 14%|‚ñà‚ñç        | 142/1028 [00:10<01:06, 13.40it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 14%|‚ñà‚ñç        | 144/1028 [00:10<01:05, 13.48it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 14%|‚ñà‚ñç        | 146/1028 [00:10<01:05, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 14%|‚ñà‚ñç        | 148/1028 [00:11<01:05, 13.47it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 1.0ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 15%|‚ñà‚ñç        | 150/1028 [00:11<01:06, 13.29it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 15%|‚ñà‚ñç        | 152/1028 [00:11<01:05, 13.33it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.4ms pre-process, 23.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 15%|‚ñà‚ñç        | 154/1028 [00:11<01:05, 13.34it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.4ms pre-process, 23.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 15%|‚ñà‚ñå        | 156/1028 [00:11<01:05, 13.35it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.6ms pre-process, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 15%|‚ñà‚ñå        | 158/1028 [00:11<01:04, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.5ms pre-process, 23.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.4ms pre-process, 23.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 16%|‚ñà‚ñå        | 160/1028 [00:12<01:03, 13.61it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 16%|‚ñà‚ñå        | 162/1028 [00:12<01:03, 13.65it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 16%|‚ñà‚ñå        | 164/1028 [00:12<01:03, 13.60it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.6ms pre-process, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 16%|‚ñà‚ñå        | 166/1028 [00:12<01:04, 13.33it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 16%|‚ñà‚ñã        | 168/1028 [00:12<01:04, 13.28it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 17%|‚ñà‚ñã        | 170/1028 [00:12<01:04, 13.40it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.4ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 17%|‚ñà‚ñã        | 172/1028 [00:12<01:03, 13.44it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 17%|‚ñà‚ñã        | 174/1028 [00:13<01:03, 13.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.6ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 17%|‚ñà‚ñã        | 176/1028 [00:13<01:02, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.4ms pre-process, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 17%|‚ñà‚ñã        | 178/1028 [00:13<01:02, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 18%|‚ñà‚ñä        | 180/1028 [00:13<01:02, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 18%|‚ñà‚ñä        | 182/1028 [00:13<01:02, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 18%|‚ñà‚ñä        | 184/1028 [00:13<01:02, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 18%|‚ñà‚ñä        | 186/1028 [00:13<01:02, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 18%|‚ñà‚ñä        | 188/1028 [00:14<01:01, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.4ms pre-process, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.6ms\n",
      "Speed: 0.5ms pre-process, 25.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 18%|‚ñà‚ñä        | 190/1028 [00:14<01:01, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 19%|‚ñà‚ñä        | 192/1028 [00:14<01:01, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 19%|‚ñà‚ñâ        | 194/1028 [00:14<01:01, 13.60it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 19%|‚ñà‚ñâ        | 196/1028 [00:14<01:01, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 1.0ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 19%|‚ñà‚ñâ        | 198/1028 [00:14<01:01, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 19%|‚ñà‚ñâ        | 200/1028 [00:14<01:01, 13.56it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.4ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 20%|‚ñà‚ñâ        | 202/1028 [00:15<01:00, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.4ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 20%|‚ñà‚ñâ        | 204/1028 [00:15<01:00, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.8ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 20%|‚ñà‚ñà        | 206/1028 [00:15<01:02, 13.21it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 20%|‚ñà‚ñà        | 208/1028 [00:15<01:01, 13.37it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 20%|‚ñà‚ñà        | 210/1028 [00:15<01:00, 13.44it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 21%|‚ñà‚ñà        | 212/1028 [00:15<01:00, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 21%|‚ñà‚ñà        | 214/1028 [00:16<00:59, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 21%|‚ñà‚ñà        | 216/1028 [00:16<00:59, 13.60it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.9ms\n",
      "Speed: 0.6ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 21%|‚ñà‚ñà        | 218/1028 [00:16<00:59, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.1ms\n",
      "Speed: 0.6ms pre-process, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 21%|‚ñà‚ñà‚ñè       | 220/1028 [00:16<00:59, 13.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 vase, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 22%|‚ñà‚ñà‚ñè       | 222/1028 [00:16<00:59, 13.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 22%|‚ñà‚ñà‚ñè       | 224/1028 [00:16<00:59, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 22%|‚ñà‚ñà‚ñè       | 226/1028 [00:16<00:59, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 22%|‚ñà‚ñà‚ñè       | 228/1028 [00:17<00:59, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 22%|‚ñà‚ñà‚ñè       | 230/1028 [00:17<00:58, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 23%|‚ñà‚ñà‚ñé       | 232/1028 [00:17<00:58, 13.60it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 23%|‚ñà‚ñà‚ñé       | 234/1028 [00:17<00:58, 13.59it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.7ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 23%|‚ñà‚ñà‚ñé       | 236/1028 [00:17<00:58, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 23%|‚ñà‚ñà‚ñé       | 238/1028 [00:17<00:57, 13.65it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 23%|‚ñà‚ñà‚ñé       | 240/1028 [00:17<00:57, 13.66it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 24%|‚ñà‚ñà‚ñé       | 242/1028 [00:18<00:57, 13.61it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 24%|‚ñà‚ñà‚ñé       | 244/1028 [00:18<00:57, 13.64it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 24%|‚ñà‚ñà‚ñç       | 246/1028 [00:18<00:57, 13.62it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 24%|‚ñà‚ñà‚ñç       | 248/1028 [00:18<00:57, 13.63it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 1 refrigerator, 25.6ms\n",
      "Speed: 0.5ms pre-process, 25.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 24%|‚ñà‚ñà‚ñç       | 250/1028 [00:18<00:57, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 25%|‚ñà‚ñà‚ñç       | 252/1028 [00:18<00:57, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 25%|‚ñà‚ñà‚ñç       | 254/1028 [00:18<00:57, 13.47it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 25%|‚ñà‚ñà‚ñç       | 256/1028 [00:19<00:57, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 25%|‚ñà‚ñà‚ñå       | 258/1028 [00:19<00:56, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 25%|‚ñà‚ñà‚ñå       | 260/1028 [00:19<00:56, 13.52it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 25%|‚ñà‚ñà‚ñå       | 262/1028 [00:19<00:56, 13.59it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 26%|‚ñà‚ñà‚ñå       | 264/1028 [00:19<00:56, 13.61it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 26%|‚ñà‚ñà‚ñå       | 266/1028 [00:19<00:55, 13.64it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 26%|‚ñà‚ñà‚ñå       | 268/1028 [00:19<00:55, 13.69it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 26%|‚ñà‚ñà‚ñã       | 270/1028 [00:20<00:55, 13.71it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 26%|‚ñà‚ñà‚ñã       | 272/1028 [00:20<00:55, 13.64it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.9ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 27%|‚ñà‚ñà‚ñã       | 274/1028 [00:20<00:56, 13.38it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 27%|‚ñà‚ñà‚ñã       | 276/1028 [00:20<00:55, 13.49it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 27%|‚ñà‚ñà‚ñã       | 278/1028 [00:20<00:55, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.6ms pre-process, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 27%|‚ñà‚ñà‚ñã       | 280/1028 [00:20<00:55, 13.47it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.6ms pre-process, 25.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 27%|‚ñà‚ñà‚ñã       | 282/1028 [00:21<00:55, 13.45it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 28%|‚ñà‚ñà‚ñä       | 284/1028 [00:21<00:55, 13.48it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 28%|‚ñà‚ñà‚ñä       | 286/1028 [00:21<00:54, 13.49it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.9ms\n",
      "Speed: 0.4ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 28%|‚ñà‚ñà‚ñä       | 288/1028 [00:21<00:55, 13.43it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.4ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 28%|‚ñà‚ñà‚ñä       | 290/1028 [00:21<00:54, 13.51it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 28%|‚ñà‚ñà‚ñä       | 292/1028 [00:21<00:54, 13.54it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.9ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 29%|‚ñà‚ñà‚ñä       | 294/1028 [00:21<00:54, 13.59it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 29%|‚ñà‚ñà‚ñâ       | 296/1028 [00:22<00:53, 13.59it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.4ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 29%|‚ñà‚ñà‚ñâ       | 298/1028 [00:22<00:53, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 29%|‚ñà‚ñà‚ñâ       | 300/1028 [00:22<00:54, 13.28it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.4ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 29%|‚ñà‚ñà‚ñâ       | 302/1028 [00:22<00:54, 13.40it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.1ms\n",
      "Speed: 1.2ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 30%|‚ñà‚ñà‚ñâ       | 304/1028 [00:22<00:54, 13.33it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 30%|‚ñà‚ñà‚ñâ       | 306/1028 [00:22<00:53, 13.39it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.6ms pre-process, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.7ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 30%|‚ñà‚ñà‚ñâ       | 308/1028 [00:22<00:53, 13.41it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 30%|‚ñà‚ñà‚ñà       | 310/1028 [00:23<00:53, 13.38it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 30%|‚ñà‚ñà‚ñà       | 312/1028 [00:23<00:53, 13.47it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 31%|‚ñà‚ñà‚ñà       | 314/1028 [00:23<00:52, 13.51it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 31%|‚ñà‚ñà‚ñà       | 316/1028 [00:23<00:52, 13.63it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 31%|‚ñà‚ñà‚ñà       | 318/1028 [00:23<00:52, 13.63it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.4ms pre-process, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 31%|‚ñà‚ñà‚ñà       | 320/1028 [00:23<00:51, 13.63it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 322/1028 [00:23<00:51, 13.66it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 324/1028 [00:24<00:51, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 326/1028 [00:24<00:51, 13.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 328/1028 [00:24<00:51, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 330/1028 [00:24<00:51, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 332/1028 [00:24<00:51, 13.43it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 334/1028 [00:24<00:51, 13.47it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 1 vase, 25.2ms\n",
      "Speed: 0.4ms pre-process, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 336/1028 [00:25<00:51, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 1.1ms pre-process, 24.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 338/1028 [00:25<00:51, 13.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 340/1028 [00:25<00:51, 13.45it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 342/1028 [00:25<00:50, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.9ms\n",
      "Speed: 1.1ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 344/1028 [00:25<00:50, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 34%|‚ñà‚ñà‚ñà‚ñé      | 346/1028 [00:25<00:50, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.7ms\n",
      "Speed: 0.4ms pre-process, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 348/1028 [00:25<00:50, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 350/1028 [00:26<00:49, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.9ms pre-process, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 352/1028 [00:26<00:49, 13.56it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 354/1028 [00:26<00:49, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 356/1028 [00:26<00:51, 13.08it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 358/1028 [00:26<00:50, 13.22it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 360/1028 [00:26<00:50, 13.21it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 362/1028 [00:26<00:50, 13.29it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.4ms pre-process, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 364/1028 [00:27<00:50, 13.25it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 366/1028 [00:27<00:49, 13.37it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 368/1028 [00:27<00:49, 13.42it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 370/1028 [00:27<00:49, 13.43it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 372/1028 [00:27<00:48, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 36%|‚ñà‚ñà‚ñà‚ñã      | 374/1028 [00:27<00:48, 13.49it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 376/1028 [00:28<00:48, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 378/1028 [00:28<00:48, 13.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 380/1028 [00:28<00:48, 13.24it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 382/1028 [00:28<00:48, 13.32it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 384/1028 [00:28<00:47, 13.44it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 386/1028 [00:28<00:47, 13.42it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 388/1028 [00:28<00:47, 13.39it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 390/1028 [00:29<00:47, 13.45it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 392/1028 [00:29<00:47, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 394/1028 [00:29<00:47, 13.47it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 396/1028 [00:29<00:47, 13.34it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 398/1028 [00:29<00:46, 13.41it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 400/1028 [00:29<00:46, 13.49it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.7ms pre-process, 24.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 402/1028 [00:29<00:46, 13.35it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.8ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 404/1028 [00:30<00:47, 13.12it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 406/1028 [00:30<00:47, 13.19it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.4ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 408/1028 [00:30<00:47, 13.08it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 410/1028 [00:30<00:46, 13.21it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 412/1028 [00:30<00:46, 13.28it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 414/1028 [00:30<00:45, 13.39it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 416/1028 [00:31<00:45, 13.48it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 418/1028 [00:31<00:45, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 420/1028 [00:31<00:45, 13.43it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 422/1028 [00:31<00:45, 13.31it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 424/1028 [00:31<00:42, 14.27it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 426/1028 [00:31<00:42, 14.08it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.7ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 428/1028 [00:31<00:43, 13.90it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 430/1028 [00:32<00:43, 13.82it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 432/1028 [00:32<00:43, 13.66it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 1.0ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 434/1028 [00:32<00:43, 13.66it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.6ms pre-process, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 436/1028 [00:32<00:43, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 438/1028 [00:32<00:43, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 440/1028 [00:32<00:43, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 442/1028 [00:32<00:43, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 444/1028 [00:33<00:43, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 446/1028 [00:33<00:43, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 448/1028 [00:33<00:42, 13.56it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 450/1028 [00:33<00:43, 13.41it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 452/1028 [00:33<00:42, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.7ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 454/1028 [00:33<00:42, 13.40it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 456/1028 [00:33<00:42, 13.44it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 458/1028 [00:34<00:42, 13.53it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 460/1028 [00:34<00:42, 13.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.7ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 462/1028 [00:34<00:39, 14.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 464/1028 [00:34<00:39, 14.15it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 466/1028 [00:34<00:40, 13.99it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 468/1028 [00:34<00:40, 13.87it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 470/1028 [00:34<00:40, 13.83it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 472/1028 [00:35<00:41, 13.39it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 1.2ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 474/1028 [00:35<00:41, 13.31it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 476/1028 [00:35<00:41, 13.39it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 25.3ms\n",
      "Speed: 0.5ms pre-process, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 478/1028 [00:35<00:41, 13.38it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.4ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 480/1028 [00:35<00:40, 13.44it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 482/1028 [00:35<00:40, 13.36it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 484/1028 [00:36<00:40, 13.42it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.7ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 486/1028 [00:36<00:40, 13.49it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 488/1028 [00:36<00:39, 13.57it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 490/1028 [00:36<00:39, 13.60it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 492/1028 [00:36<00:39, 13.58it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 494/1028 [00:36<00:39, 13.57it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 496/1028 [00:36<00:39, 13.60it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 498/1028 [00:37<00:38, 13.66it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 500/1028 [00:37<00:39, 13.23it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 502/1028 [00:37<00:39, 13.29it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.4ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 504/1028 [00:37<00:39, 13.37it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.7ms\n",
      "Speed: 0.5ms pre-process, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.3ms\n",
      "Speed: 0.5ms pre-process, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 506/1028 [00:37<00:39, 13.19it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 508/1028 [00:37<00:39, 13.30it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 510/1028 [00:37<00:38, 13.32it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 512/1028 [00:38<00:38, 13.39it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 514/1028 [00:38<00:38, 13.43it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 516/1028 [00:38<00:37, 13.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 518/1028 [00:38<00:37, 13.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 520/1028 [00:38<00:37, 13.55it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 522/1028 [00:38<00:37, 13.58it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 524/1028 [00:38<00:37, 13.55it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 526/1028 [00:39<00:36, 13.59it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 528/1028 [00:39<00:36, 13.56it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 530/1028 [00:39<00:36, 13.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.7ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 532/1028 [00:39<00:37, 13.26it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 534/1028 [00:39<00:37, 13.29it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 536/1028 [00:39<00:36, 13.33it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 538/1028 [00:40<00:37, 13.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 540/1028 [00:40<00:37, 13.02it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.4ms pre-process, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 542/1028 [00:40<00:37, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 544/1028 [00:40<00:36, 13.10it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 546/1028 [00:40<00:37, 12.97it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 548/1028 [00:40<00:36, 13.03it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 1.2ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 550/1028 [00:40<00:36, 13.16it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.7ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 552/1028 [00:41<00:36, 13.21it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 554/1028 [00:41<00:36, 13.09it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 556/1028 [00:41<00:36, 13.05it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.4ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 558/1028 [00:41<00:35, 13.19it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.4ms pre-process, 23.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 560/1028 [00:41<00:35, 13.34it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 562/1028 [00:41<00:34, 13.41it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.6ms pre-process, 23.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.5ms pre-process, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 564/1028 [00:42<00:34, 13.31it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.4ms pre-process, 23.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 566/1028 [00:42<00:35, 13.07it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.4ms pre-process, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.6ms pre-process, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 568/1028 [00:42<00:34, 13.22it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.5ms pre-process, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 570/1028 [00:42<00:34, 13.27it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.5ms pre-process, 23.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 572/1028 [00:42<00:33, 13.44it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.4ms pre-process, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 574/1028 [00:42<00:34, 13.35it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.6ms pre-process, 23.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 576/1028 [00:42<00:33, 13.32it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.4ms pre-process, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 578/1028 [00:43<00:33, 13.33it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.6ms pre-process, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 580/1028 [00:43<00:34, 13.18it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.8ms pre-process, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 582/1028 [00:43<00:33, 13.26it/s]\n",
      "0: 640x640 1 person, 1 sports ball, 2 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.4ms pre-process, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 584/1028 [00:43<00:33, 13.20it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 586/1028 [00:43<00:34, 12.97it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 588/1028 [00:43<00:33, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.9ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 590/1028 [00:43<00:33, 12.96it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 592/1028 [00:44<00:33, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.7ms pre-process, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 594/1028 [00:44<00:33, 13.07it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.7ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 596/1028 [00:44<00:32, 13.16it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 598/1028 [00:44<00:33, 12.97it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 600/1028 [00:44<00:32, 13.06it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 602/1028 [00:44<00:32, 13.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 604/1028 [00:45<00:32, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 606/1028 [00:45<00:33, 12.72it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 608/1028 [00:45<00:32, 12.90it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.7ms pre-process, 23.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 610/1028 [00:45<00:32, 13.05it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.6ms pre-process, 23.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.3ms\n",
      "Speed: 0.5ms pre-process, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 612/1028 [00:45<00:31, 13.14it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.6ms pre-process, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 614/1028 [00:45<00:32, 12.85it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.5ms pre-process, 23.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 616/1028 [00:45<00:31, 12.95it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.5ms pre-process, 23.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.5ms pre-process, 23.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 618/1028 [00:46<00:31, 12.93it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.7ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 620/1028 [00:46<00:32, 12.70it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.6ms pre-process, 23.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.4ms pre-process, 23.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 622/1028 [00:46<00:31, 12.84it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.4ms\n",
      "Speed: 0.5ms pre-process, 23.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.6ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 624/1028 [00:46<00:31, 12.94it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.5ms pre-process, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 626/1028 [00:46<00:30, 13.07it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.2ms\n",
      "Speed: 0.5ms pre-process, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 628/1028 [00:46<00:30, 13.12it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.5ms pre-process, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.6ms pre-process, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 630/1028 [00:47<00:30, 13.10it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.7ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 632/1028 [00:47<00:30, 12.91it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 634/1028 [00:47<00:30, 12.87it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 636/1028 [00:47<00:30, 12.96it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.8ms pre-process, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 638/1028 [00:47<00:30, 12.99it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 640/1028 [00:47<00:29, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 642/1028 [00:47<00:29, 12.99it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.6ms\n",
      "Speed: 0.5ms pre-process, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 644/1028 [00:48<00:29, 13.06it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.3ms\n",
      "Speed: 0.5ms pre-process, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 646/1028 [00:48<00:29, 12.88it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.7ms pre-process, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.8ms\n",
      "Speed: 0.6ms pre-process, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 648/1028 [00:48<00:29, 12.89it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.7ms\n",
      "Speed: 0.6ms pre-process, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.3ms\n",
      "Speed: 0.5ms pre-process, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 650/1028 [00:48<00:29, 12.76it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.4ms\n",
      "Speed: 0.5ms pre-process, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.3ms\n",
      "Speed: 0.5ms pre-process, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 652/1028 [00:48<00:29, 12.68it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.8ms\n",
      "Speed: 0.5ms pre-process, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.1ms\n",
      "Speed: 0.5ms pre-process, 26.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 654/1028 [00:48<00:29, 12.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.6ms\n",
      "Speed: 0.5ms pre-process, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.9ms\n",
      "Speed: 0.5ms pre-process, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 656/1028 [00:49<00:29, 12.45it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.5ms\n",
      "Speed: 0.8ms pre-process, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.0ms\n",
      "Speed: 0.6ms pre-process, 26.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 658/1028 [00:49<00:30, 12.18it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 27.2ms\n",
      "Speed: 0.9ms pre-process, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.5ms\n",
      "Speed: 0.6ms pre-process, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 660/1028 [00:49<00:30, 12.00it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.9ms\n",
      "Speed: 0.5ms pre-process, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 662/1028 [00:49<00:29, 12.28it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.6ms pre-process, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 664/1028 [00:49<00:30, 12.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.6ms pre-process, 24.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 666/1028 [00:49<00:29, 12.10it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 668/1028 [00:50<00:29, 12.22it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 670/1028 [00:50<00:29, 12.27it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.5ms pre-process, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 672/1028 [00:50<00:28, 12.30it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 674/1028 [00:50<00:28, 12.36it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 676/1028 [00:50<00:28, 12.38it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 678/1028 [00:50<00:27, 12.54it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 1.2ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 680/1028 [00:51<00:27, 12.62it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 682/1028 [00:51<00:27, 12.76it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 684/1028 [00:51<00:27, 12.71it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.9ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 686/1028 [00:51<00:27, 12.66it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 688/1028 [00:51<00:27, 12.52it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 690/1028 [00:51<00:27, 12.48it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 692/1028 [00:52<00:26, 12.50it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.7ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 694/1028 [00:52<00:26, 12.75it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 696/1028 [00:52<00:25, 12.86it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 698/1028 [00:52<00:25, 12.97it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.9ms pre-process, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.8ms pre-process, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 700/1028 [00:52<00:27, 11.83it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 702/1028 [00:52<00:26, 12.11it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.0ms\n",
      "Speed: 0.5ms pre-process, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 704/1028 [00:52<00:26, 12.36it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 26.3ms\n",
      "Speed: 0.5ms pre-process, 26.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.4ms\n",
      "Speed: 0.5ms pre-process, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 706/1028 [00:53<00:25, 12.43it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 708/1028 [00:53<00:25, 12.64it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.7ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 710/1028 [00:53<00:24, 12.78it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 712/1028 [00:53<00:24, 12.82it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 714/1028 [00:53<00:25, 12.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 716/1028 [00:53<00:24, 12.70it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 718/1028 [00:54<00:24, 12.77it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 720/1028 [00:54<00:23, 12.86it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 722/1028 [00:54<00:23, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 724/1028 [00:54<00:23, 13.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 726/1028 [00:54<00:22, 13.17it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.8ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 728/1028 [00:54<00:22, 13.06it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 730/1028 [00:54<00:22, 13.06it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.4ms pre-process, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 732/1028 [00:55<00:22, 13.02it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.9ms\n",
      "Speed: 0.4ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 734/1028 [00:55<00:22, 13.06it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.7ms pre-process, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.0ms\n",
      "Speed: 0.6ms pre-process, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 736/1028 [00:55<00:22, 13.09it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 738/1028 [00:55<00:22, 13.09it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 740/1028 [00:55<00:21, 13.12it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 742/1028 [00:55<00:22, 12.81it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 744/1028 [00:56<00:21, 12.93it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 746/1028 [00:56<00:21, 12.89it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.8ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 748/1028 [00:56<00:21, 12.84it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 750/1028 [00:56<00:21, 12.71it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.7ms pre-process, 24.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 752/1028 [00:56<00:21, 12.75it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 754/1028 [00:56<00:21, 12.86it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 1.1ms pre-process, 24.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 756/1028 [00:57<00:21, 12.57it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 758/1028 [00:57<00:21, 12.73it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 760/1028 [00:57<00:20, 12.76it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 762/1028 [00:57<00:20, 12.89it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 764/1028 [00:57<00:20, 13.01it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 766/1028 [00:57<00:20, 13.02it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 768/1028 [00:57<00:20, 12.92it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 770/1028 [00:58<00:20, 12.56it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 1.2ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 772/1028 [00:58<00:20, 12.46it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 774/1028 [00:58<00:20, 12.48it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 776/1028 [00:58<00:20, 12.57it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 778/1028 [00:58<00:20, 12.34it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.8ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 780/1028 [00:58<00:19, 12.47it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 782/1028 [00:59<00:19, 12.46it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 784/1028 [00:59<00:19, 12.51it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.6ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 786/1028 [00:59<00:19, 12.63it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 788/1028 [00:59<00:18, 12.70it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 790/1028 [00:59<00:18, 12.62it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.7ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 792/1028 [00:59<00:18, 12.72it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 794/1028 [01:00<00:18, 12.85it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 796/1028 [01:00<00:17, 12.89it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 798/1028 [01:00<00:17, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 800/1028 [01:00<00:17, 12.71it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 802/1028 [01:00<00:17, 12.86it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 804/1028 [01:00<00:17, 12.95it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.6ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 806/1028 [01:00<00:17, 12.90it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 808/1028 [01:01<00:16, 12.96it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 810/1028 [01:01<00:16, 12.96it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 812/1028 [01:01<00:17, 12.59it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 814/1028 [01:01<00:16, 12.80it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 816/1028 [01:01<00:16, 12.84it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.7ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 818/1028 [01:01<00:16, 12.95it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 820/1028 [01:02<00:16, 13.00it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 822/1028 [01:02<00:15, 13.05it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 824/1028 [01:02<00:15, 13.07it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 826/1028 [01:02<00:15, 13.04it/s]\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 24.0ms\n",
      "Speed: 0.4ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.5ms pre-process, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 828/1028 [01:02<00:15, 13.09it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.6ms pre-process, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 2 apples, 1 donut, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 830/1028 [01:02<00:15, 13.02it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.2ms\n",
      "Speed: 0.6ms pre-process, 25.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 832/1028 [01:02<00:15, 13.04it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.4ms pre-process, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 834/1028 [01:03<00:15, 12.75it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 836/1028 [01:03<00:14, 12.82it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 838/1028 [01:03<00:14, 12.89it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.8ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 840/1028 [01:03<00:14, 13.00it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 842/1028 [01:03<00:14, 12.99it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 844/1028 [01:03<00:14, 12.94it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 846/1028 [01:04<00:14, 12.99it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 848/1028 [01:04<00:13, 13.10it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 850/1028 [01:04<00:13, 13.17it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 852/1028 [01:04<00:13, 13.16it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.9ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 854/1028 [01:04<00:13, 12.94it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 856/1028 [01:04<00:13, 12.95it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 858/1028 [01:04<00:13, 12.92it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 860/1028 [01:05<00:12, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 862/1028 [01:05<00:12, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 864/1028 [01:05<00:12, 13.07it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 866/1028 [01:05<00:12, 13.15it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.7ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 868/1028 [01:05<00:12, 12.91it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 870/1028 [01:05<00:12, 12.99it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 872/1028 [01:06<00:12, 12.93it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.7ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 874/1028 [01:06<00:11, 12.99it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 876/1028 [01:06<00:11, 13.09it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.0ms\n",
      "Speed: 1.2ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 878/1028 [01:06<00:11, 12.95it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.4ms pre-process, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 880/1028 [01:06<00:11, 12.76it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.7ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 882/1028 [01:06<00:11, 12.75it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.6ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 884/1028 [01:06<00:11, 12.81it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.1ms\n",
      "Speed: 0.5ms pre-process, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 886/1028 [01:07<00:11, 12.84it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.8ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.3ms\n",
      "Speed: 0.4ms pre-process, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 888/1028 [01:07<00:10, 12.90it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 25.3ms\n",
      "Speed: 0.6ms pre-process, 25.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 890/1028 [01:07<00:10, 12.71it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 892/1028 [01:07<00:10, 12.72it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.6ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.9ms\n",
      "Speed: 0.5ms pre-process, 24.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 894/1028 [01:07<00:10, 12.81it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 896/1028 [01:07<00:10, 12.79it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 898/1028 [01:08<00:10, 12.82it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.7ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 900/1028 [01:08<00:10, 12.60it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 902/1028 [01:08<00:09, 12.74it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.6ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 904/1028 [01:08<00:09, 12.90it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.8ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 906/1028 [01:08<00:09, 12.90it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 1.1ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 908/1028 [01:08<00:09, 13.05it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 910/1028 [01:08<00:09, 12.87it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 912/1028 [01:09<00:09, 12.88it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 914/1028 [01:09<00:08, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 916/1028 [01:09<00:08, 13.04it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 918/1028 [01:09<00:08, 13.13it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 920/1028 [01:09<00:08, 12.97it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.8ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 922/1028 [01:09<00:08, 13.04it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 924/1028 [01:10<00:08, 13.00it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 926/1028 [01:10<00:07, 13.07it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.7ms\n",
      "Speed: 0.6ms pre-process, 23.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 928/1028 [01:10<00:07, 13.08it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 930/1028 [01:10<00:07, 13.14it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 932/1028 [01:10<00:07, 13.09it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.9ms\n",
      "Speed: 0.7ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 934/1028 [01:10<00:07, 13.11it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.7ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.4ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 936/1028 [01:10<00:06, 13.16it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.5ms\n",
      "Speed: 0.4ms pre-process, 24.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 938/1028 [01:11<00:06, 13.20it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.4ms pre-process, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 940/1028 [01:11<00:06, 13.21it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.6ms pre-process, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 942/1028 [01:11<00:06, 13.15it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 944/1028 [01:11<00:06, 13.20it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.4ms pre-process, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.0ms\n",
      "Speed: 0.5ms pre-process, 25.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 946/1028 [01:11<00:06, 13.17it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 948/1028 [01:11<00:06, 13.12it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 950/1028 [01:12<00:06, 13.00it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.5ms pre-process, 24.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 952/1028 [01:12<00:05, 13.02it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 1.1ms pre-process, 24.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 954/1028 [01:12<00:05, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 956/1028 [01:12<00:05, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 958/1028 [01:12<00:05, 13.11it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 960/1028 [01:12<00:05, 13.16it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 962/1028 [01:12<00:05, 13.03it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 964/1028 [01:13<00:04, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 966/1028 [01:13<00:04, 13.11it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 968/1028 [01:13<00:04, 13.11it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.5ms pre-process, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.6ms pre-process, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 970/1028 [01:13<00:04, 13.17it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 972/1028 [01:13<00:04, 13.14it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.4ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 974/1028 [01:13<00:04, 13.19it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.5ms pre-process, 24.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.7ms pre-process, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 976/1028 [01:14<00:03, 13.18it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.3ms\n",
      "Speed: 0.5ms pre-process, 25.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 978/1028 [01:14<00:03, 13.23it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.5ms\n",
      "Speed: 0.6ms pre-process, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 980/1028 [01:14<00:03, 13.21it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 982/1028 [01:14<00:03, 13.20it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.5ms pre-process, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 984/1028 [01:14<00:03, 13.02it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.3ms\n",
      "Speed: 0.6ms pre-process, 24.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 986/1028 [01:14<00:03, 13.05it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 0.7ms pre-process, 24.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 988/1028 [01:14<00:03, 13.01it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.1ms\n",
      "Speed: 1.0ms pre-process, 24.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 990/1028 [01:15<00:02, 13.10it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 992/1028 [01:15<00:02, 12.89it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.4ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 994/1028 [01:15<00:02, 12.98it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.4ms\n",
      "Speed: 0.6ms pre-process, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 996/1028 [01:15<00:02, 12.95it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.8ms\n",
      "Speed: 0.5ms pre-process, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 1 refrigerator, 24.2ms\n",
      "Speed: 0.6ms pre-process, 24.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 998/1028 [01:15<00:02, 12.67it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.5ms pre-process, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1000/1028 [01:15<00:02, 12.78it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.2ms\n",
      "Speed: 0.5ms pre-process, 24.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.7ms\n",
      "Speed: 0.5ms pre-process, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1002/1028 [01:16<00:02, 12.84it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.7ms\n",
      "Speed: 0.5ms pre-process, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 25.5ms\n",
      "Speed: 0.6ms pre-process, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1004/1028 [01:16<00:01, 12.69it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.6ms\n",
      "Speed: 0.7ms pre-process, 24.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.8ms\n",
      "Speed: 0.4ms pre-process, 23.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1006/1028 [01:16<00:01, 12.69it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.7ms\n",
      "Speed: 0.4ms pre-process, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1008/1028 [01:16<00:01, 12.82it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.5ms pre-process, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1010/1028 [01:16<00:01, 12.95it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.5ms\n",
      "Speed: 0.7ms pre-process, 23.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1012/1028 [01:16<00:01, 13.10it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.7ms pre-process, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1014/1028 [01:16<00:01, 12.70it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.9ms\n",
      "Speed: 0.5ms pre-process, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1016/1028 [01:17<00:00, 13.67it/s]\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 24.0ms\n",
      "Speed: 0.5ms pre-process, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 person, 3 apples, 1 dining table, 23.6ms\n",
      "Speed: 0.5ms pre-process, 23.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1028/1028 [01:17<00:00, 13.26it/s]\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "out_img_list = []\n",
    "dataset = []\n",
    "status = 'None'\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1,\n",
    "                    enable_segmentation = False, min_detection_confidence=0.3)\n",
    "\n",
    "print(\"ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...\")\n",
    "\n",
    "\n",
    "xy_list_list = []\n",
    "for img in tqdm(img_list):\n",
    "    results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if not results.pose_landmarks: continue\n",
    "    xy_list = []\n",
    "    idx = 0\n",
    "    draw_line_dic = {}\n",
    "    \n",
    "    yolo_result = model(img, agnostic_nms=True)[0]\n",
    "    detections = sv.Detections.from_yolov8(yolo_result)\n",
    "    \n",
    "    selected_classes = [47]  # # 46: banana, 47 : apple, 49: orange \n",
    "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
    "    \n",
    "    labels = [f\"{model.model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "    \n",
    "    for x_and_y in results.pose_landmarks.landmark:\n",
    "        if idx in attention_dot:\n",
    "            xy_list.append(x_and_y.x)\n",
    "            xy_list.append(x_and_y.y)\n",
    "            x, y = int(x_and_y.x * 640), int(x_and_y.y * 640)\n",
    "            draw_line_dic[idx] = [x, y]\n",
    "        idx += 1\n",
    "    \n",
    "    if len(detections.xyxy) == 0:\n",
    "        detected_obj = [0.0, 0.0, 0.0, 0.0]\n",
    "    else:\n",
    "        detected_obj = list(detections.xyxy[0] / 640)\n",
    "    \n",
    "    xy_list += detected_obj\n",
    "    \n",
    "    xy_list_list.append(xy_list)\n",
    "    \n",
    "    for line in draw_line:\n",
    "        x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "        x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "        img = cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "\n",
    "    img = box_annotator.annotate(\n",
    "                    scene=img, \n",
    "                    detections=detections, \n",
    "                    labels=labels\n",
    "                )\n",
    "    if len(xy_list_list) == length:\n",
    "        dataset = []\n",
    "        dataset.append({'key' : 0, 'value' : xy_list_list})\n",
    "        dataset = MyDataset(dataset)\n",
    "        dataset = DataLoader(dataset)\n",
    "        xy_list_list = []\n",
    "        for data, label in dataset:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                result = net(data)\n",
    "                _, out = torch.max(result, 1)\n",
    "                if out.item() == 0:\n",
    "                    status = 'Nothing'\n",
    "                elif out.item() == 1: \n",
    "                    status = 'Picking'\n",
    "                else:\n",
    "                    status = 'Holding'\n",
    "    \n",
    "    cv2.putText(img, status, (0, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 2)\n",
    "    out_img_list.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌÖåÏä§Ìä∏ Í≤∞Í≥º ÏòÅÏÉÅ Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "filename = '../results/test_5_result.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fps = 30\n",
    "frameSize = (640, 640)\n",
    "isColor = True\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor)\n",
    "for out_img in out_img_list:\n",
    "    out.write(out_img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time ÎèôÏûë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2713171604.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    img = cv2.flip(img, 0)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2 \n",
    "\n",
    "net.eval()\n",
    "out_img_list = []\n",
    "dataset = []\n",
    "status = ''\n",
    "action = 0\n",
    "fruit_type = 5\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1,\n",
    "                    enable_segmentation = False, min_detection_confidence=0.3)\n",
    "\n",
    "print(\"ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë...\")\n",
    "\n",
    "xy_list_list = []\n",
    "# file_path = '../log/test5.json'\n",
    "seq = {}\n",
    "seq_index = 0\n",
    "            \n",
    "img = cv2.flip(img, 0)\n",
    "img = cv2.flip(img, 1)\n",
    "results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "if not results.pose_landmarks: continue\n",
    "test_dict = {}\n",
    "xy_list = []\n",
    "idx = 0\n",
    "person = 0\n",
    "\n",
    "fruit_quantity = 0\n",
    "draw_line_dic = {}\n",
    "\n",
    "yolo_result = model(img, agnostic_nms=True)[0]\n",
    "hand_centers = get_hand_centers(results)\n",
    "\n",
    "detections = sv.Detections.from_yolov8(yolo_result)\n",
    "# selected_classes = [0, 1, 2, 3, 4]  # 46: banana, 47 : apple, 49: orange \n",
    "# detections = detections[np.isin(detections.class_id, selected_classes)]\n",
    "\n",
    "if 3 in detections.class_id:\n",
    "    person = 1\n",
    "    \n",
    "labels = [f\"{model.model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "\n",
    "\n",
    "object_centers = []\n",
    "class_ids = []\n",
    "\n",
    "# if len(detections.xyxy) == 0:\n",
    "#     detected_obj = [0.0, 0.0, 0.0, 0.0]\n",
    "# else:\n",
    "#     detected_obj = list(detections.xyxy[0] / 640)\n",
    "\n",
    "for i in range(len(detections.xyxy)):\n",
    "    x_center = ((detections.xyxy[i][0] + detections.xyxy[i][2]) / 2) / 640\n",
    "    y_center = ((detections.xyxy[i][1] + detections.xyxy[i][3]) / 2) / 640\n",
    "    object_centers.append((x_center, y_center))\n",
    "    class_ids.append(detections.class_id[i])\n",
    "\n",
    "\n",
    "min_distance = 100000\n",
    "holding_object = ''\n",
    "dist_list = []\n",
    "\n",
    "# Ïú†ÌÅ¥Î¶¨ÎîîÏñ∏ Í±∞Î¶¨ Í≥ÑÏÇ∞ Î∞è ÏµúÏÜå Í±∞Î¶¨ÏôÄ Ìï¥Îãπ Î¨ºÏ≤¥ Ïù¥Î¶Ñ Ï∂úÎ†•\n",
    "for i in range(len(detections.xyxy)):    \n",
    "    \n",
    "    # Holding left hand\n",
    "    if hand_centers[0][1] <= 0.5 and object_centers[i][1] <= 0.8 and (class_ids[i] not in [3, 4]):\n",
    "        distance = calculate_distance(object_centers[i], hand_centers[0])        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            fruit_type = class_ids[i]\n",
    "            holding_object = model.model.names[class_ids[i]]\n",
    "            fruit_quantity = 1\n",
    "            \n",
    "    # Holding right hand\n",
    "    if hand_centers[1][1] <= 0.5 and object_centers[i][1] <= 0.8 and (class_ids[i] not in [3, 4]):\n",
    "        distance = calculate_distance(object_centers[i], hand_centers[1])        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            fruit_type = class_ids[i]\n",
    "            holding_object = model.model.names[class_ids[i]]\n",
    "            fruit_quantity = 1\n",
    "    \n",
    "    # if hand_centers[0][1] <= 0.5 and object_centers[i][1] <= 0.8 and class_ids[i] not in [3, 4]:\n",
    "    #         holding_object = model.model.names[class_ids[i]]\n",
    "    \n",
    "    \n",
    "    # if hand_centers[1][1] <= 0.5 and object_centers[i][1] <= 0.8 and class_ids[i] not in [3, 4]:\n",
    "    #         holding_object = model.model.names[class_ids[i]]\n",
    "\n",
    "min_distance = round(min_distance, 3)\n",
    "for x_and_y in results.pose_landmarks.landmark:\n",
    "    if idx in attention_dot:\n",
    "        xy_list.append(x_and_y.x)\n",
    "        xy_list.append(x_and_y.y)\n",
    "        x, y = int(x_and_y.x * 640), int(x_and_y.y * 640)\n",
    "        draw_line_dic[idx] = [x, y]\n",
    "    idx += 1\n",
    "\n",
    "if len(detections.xyxy) == 0:\n",
    "    detected_obj = [0.0, 0.0, 0.0, 0.0]\n",
    "else:\n",
    "    detected_obj = list(detections.xyxy[0] / 640)\n",
    "\n",
    "xy_list += detected_obj\n",
    "xy_list_list.append(xy_list)\n",
    "\n",
    "for line in draw_line:\n",
    "    x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "    x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "    img = cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "\n",
    "img = box_annotator.annotate(\n",
    "                scene=img, \n",
    "                detections=detections, \n",
    "                labels=labels\n",
    "            )\n",
    "if len(xy_list_list) == length:\n",
    "    dataset = []\n",
    "    dataset.append({'key' : 0, 'value' : xy_list_list})\n",
    "    dataset = MyDataset(dataset)\n",
    "    dataset = DataLoader(dataset)\n",
    "    xy_list_list = []\n",
    "    for data, label in dataset:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            result = net(data)\n",
    "            _, output = torch.max(result, 1)\n",
    "            if output.item() == 0:\n",
    "                # status = f'Nothing {holding_object}, min_dist: {min_distance}'\n",
    "                status = 'Nothing' \n",
    "                fruit_type = 5\n",
    "                action = 0\n",
    "\n",
    "            elif output.item() == 1:  \n",
    "                status = 'Picking_up'\n",
    "                fruit_type = 5\n",
    "                action = 1\n",
    "                \n",
    "            elif output.item() == 2:\n",
    "                status = 'Putting_down'\n",
    "                fruit_type = 5\n",
    "                action = 2\n",
    "            elif output.item() == 3:\n",
    "                # if holding_object != '':\n",
    "                #     # status = f'Holding {holding_object}, min_dist: {min_distance}'\n",
    "                #     status = f'Holding {holding_object}'\n",
    "                # else: \n",
    "                #     status = 'Holding'\n",
    "                \n",
    "                status = 'Holding ' + holding_object \n",
    "                action = 3\n",
    "\n",
    "# Î≥¥Ï†ï ÏôÑÎ£å: person, action, fruit_type, fruit_quantity\n",
    "test_dict['person'] = int(person)\n",
    "test_dict['action'] = int(action)\n",
    "test_dict['fruit_type'] = int(fruit_type)\n",
    "test_dict['fruit_quantity'] = int(fruit_quantity)\n",
    "# print(test_dict)\n",
    "\n",
    "# cv2.putText(img, status, (0, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 2)\n",
    "cv2.putText(img, f'{status}', (0, 25), cv2.FONT_HERSHEY_COMPLEX, 1.0, (0, 0, 0), 1)\n",
    "out_img_list.append(img)\n",
    "seq[seq_index] = test_dict\n",
    "seq_index += 1\n",
    "    \n",
    "with open('../log/action_5_log.json', 'w') as f:\n",
    "     json.dump(seq, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
